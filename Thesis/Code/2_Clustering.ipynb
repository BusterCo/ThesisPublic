{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom.GeoSpatialEncoder import GeoSpatialEncoder\n",
    "from custom.PC_Class import PC\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "datetime_cols = ['CREATIONDATETIME', 'LAAD_DATETIME_VAN', 'LAAD_DATETIME_TOT', 'LOS_DATETIME_VAN', 'LOS_DATETIME_TOT', '15CREATIONDATETIME']\n",
    "direct = os.getcwd()\n",
    "file_path = direct + # PATH TO DATA FOR TRAINING HERE \n",
    "total_rows = sum(1 for row in open(file_path, 'r', encoding='utf-8'))\n",
    "chunk_size = 10000  \n",
    "tqdm.pandas(desc=\"Reading CSV\")\n",
    "chunks = pd.read_csv(file_path, chunksize=chunk_size, iterator=True, index_col = 0, parse_dates=datetime_cols)\n",
    "\n",
    "df_orders = pd.concat(tqdm(chunks, total=total_rows//chunk_size))\n",
    "\n",
    "# Convert the 'LOS_DATETIME_VAN' column to datetime format\n",
    "for column in datetime_cols:\n",
    "    print(f\"column: {column}\")\n",
    "    df_orders[column] = pd.to_datetime(df_orders[column], errors='coerce')\n",
    "\n",
    "print(\"Lenght of input data:\", str(len(df_orders)))\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = df_orders[df_orders[\"AFHCODE\"] == 'd'].groupby('OPDRACHTGEVERNAAM').agg({\n",
    "        'OPDRACHTGEVERNAAM': 'first',\n",
    "        'PALLETPLAATSEN': 'sum',\n",
    "        'SHIPMENTNUMBER': 'count'\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "\n",
    "cutoff = 365\n",
    "\n",
    "aggregated_df[aggregated_df[\"SHIPMENTNUMBER\"] > cutoff]\n",
    "companies_list = aggregated_df[aggregated_df[\"SHIPMENTNUMBER\"] > cutoff].sort_values(\"PALLETPLAATSEN\", ascending=False)[\"OPDRACHTGEVERNAAM\"].values\n",
    "included_volume = df_orders[df_orders[\"OPDRACHTGEVERNAAM\"].isin(companies_list)][\"PALLETPLAATSEN\"].sum()\n",
    "excluded_volume = df_orders[~df_orders[\"OPDRACHTGEVERNAAM\"].isin(companies_list)][\"PALLETPLAATSEN\"].sum()\n",
    "total_volume = included_volume + excluded_volume\n",
    "percentage = included_volume / total_volume * 100\n",
    "df_orders = df_orders[df_orders[\"OPDRACHTGEVERNAAM\"].isin(companies_list)]\n",
    "print(f\"Number of companies with more than 365 days of data available: {len(companies_list)}\")\n",
    "print(f\"Total volume: {total_volume}\")\n",
    "print(f\"Included volume: {included_volume}\")\n",
    "print(f\"Excluded volume: {excluded_volume}\")\n",
    "print(f\"Percentage: {percentage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_obj = PC()\n",
    "print(\"PC object created\")\n",
    "\n",
    "GSE = GeoSpatialEncoder(PC_obj)\n",
    "print(\"GSE object created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE.set_input_df(df_orders)\n",
    "print(\"GSE input set\")\n",
    "\n",
    "GSE.clean_input_df()\n",
    "print(\"GSE input cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kmeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inertia Scores Kmeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intertia scores using palletplaatsen as weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_kmeans = []\n",
    "import time\n",
    "testingsizes = list(range(1,40))\n",
    "for x in testingsizes:\n",
    "    start_time = time.time()\n",
    "    GSE.train_kmeans(x, 'PALLETPLAATSEN')\n",
    "    score = GSE.return_inertia()\n",
    "    scores_kmeans.append(score)\n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    print( f\"Trained {x} clusters in {iteration_time} with score:  {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing lists to a text file\n",
    "# with open('kmeansscoresPALLETPLAATSEN.txt', 'w') as file:\n",
    "#     file.write(','.join(map(str, testingsizes)) + '\\n')\n",
    "#     file.write(','.join(map(str, scores_kmeans)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kmeansscoresPALLETPLAATSEN.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    testingsizes = lines[0].strip().split(',')\n",
    "    scores_kmeans = lines[1].strip().split(',')\n",
    "    #convert all elements to int\n",
    "    scores_kmeans = [float(i) for i in scores_kmeans]\n",
    "    testingsizes = [int(i) for i in testingsizes]\n",
    "\n",
    "print(testingsizes)  \n",
    "print(scores_kmeans)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(testingsizes, scores_kmeans, 'bo-', linewidth=2)\n",
    "# plt.xlabel('Number of clusters (k)')\n",
    "# plt.ylabel('Inertia Score')\n",
    "# plt.title('Elbow Graph for KMeans Clustering (Inertia Score; Weighed by number of pallets)')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE.train_kmeans(8, 'PALLETPLAATSEN')\n",
    "GSE.plot_clusters('kmeans', '8 clusters for all companies weighed by number of pallets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intertia scores using ordercount as weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a single company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE = GeoSpatialEncoder(PC_obj)\n",
    "input_temp = df_orders[df_orders[\"OPDRACHTGEVERNAAM\"] == 'PAARDEKOOPER_BV']\n",
    "GSE.set_input_df(input_temp)\n",
    "GSE.clean_input_df()\n",
    "\n",
    "scores_kmeans = []\n",
    "import time\n",
    "testingsizes = list(range(1,40))\n",
    "for x in testingsizes:\n",
    "    start_time = time.time()\n",
    "    GSE.train_kmeans(x, 'SHIPMENT_COUNT')\n",
    "    score = GSE.return_inertia()\n",
    "    scores_kmeans.append(score)\n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    print( f\"Trained {x} clusters in {iteration_time} with score:  {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(testingsizes, scores_kmeans, 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia Score')\n",
    "plt.title('Elbow Graph for KMeans Clustering for Company A (Inertia Score; Weighed by order count)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For multiple companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE = GeoSpatialEncoder(PC_obj)\n",
    "\n",
    "GSE.set_input_df(df_orders)\n",
    "GSE.clean_input_df()\n",
    "\n",
    "scores_kmeans = []\n",
    "import time\n",
    "testingsizes = list(range(1,40))\n",
    "for x in testingsizes:\n",
    "    start_time = time.time()\n",
    "    GSE.train_kmeans(x, 'SHIPMENT_COUNT')\n",
    "    score = GSE.return_inertia()\n",
    "    scores_kmeans.append(score)\n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    print( f\"Trained {x} clusters in {iteration_time} with score:  {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing lists to a text file\n",
    "# with open('kmeansscoresSHIPMENTCOUNT.txt', 'w') as file:\n",
    "#     file.write(','.join(map(str, testingsizes)) + '\\n')\n",
    "#     file.write(','.join(map(str, scores_kmeans)) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kmeansscoresSHIPMENTCOUNT.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    testingsizes = lines[0].strip().split(',')\n",
    "    scores_kmeans = lines[1].strip().split(',')\n",
    "    #convert all elements to int\n",
    "    scores_kmeans = [float(i) for i in scores_kmeans]\n",
    "    testingsizes = [int(i) for i in testingsizes]\n",
    "\n",
    "print(testingsizes)  \n",
    "print(scores_kmeans)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(testingsizes, scores_kmeans, 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia Score')\n",
    "plt.title('Elbow Graph for KMeans Clustering (Inertia Score; Weighed by number of orders)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE.train_kmeans(4, 'SHIPMENT_COUNT')\n",
    "GSE.plot_clusters('kmeans', '4 clusters for all companies weighed by number of pallets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For a single company\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE = GeoSpatialEncoder(PC_obj)\n",
    "input_temp = df_orders[df_orders[\"OPDRACHTGEVERNAAM\"] == ''] #SAMPLE COMPANY HERE\n",
    "GSE.set_input_df(input_temp)\n",
    "GSE.clean_input_df()\n",
    "\n",
    "scores = []\n",
    "import time\n",
    "testingsizes = list(range(2,80))\n",
    "for x in testingsizes:\n",
    "    start_time = time.time()\n",
    "    GSE.train_agglomerative(x)\n",
    "    score = GSE.return_silhouette_score()\n",
    "    scores.append(score)\n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    print( f\"Trained {x} clusters in {iteration_time} with score:  {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(testingsizes, scores, 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Elbow Graph for Company A using Agglomerative Clustering (Silhouette Score)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For multiple companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE = GeoSpatialEncoder(PC_obj)\n",
    "\n",
    "GSE.set_input_df(df_orders)\n",
    "GSE.clean_input_df()\n",
    "\n",
    "scores = []\n",
    "import time\n",
    "testingsizes = list(range(2,80))\n",
    "for x in testingsizes:\n",
    "    start_time = time.time()\n",
    "    GSE.train_agglomerative(x)\n",
    "    score = GSE.return_silhouette_score()\n",
    "    scores.append(score)\n",
    "    end_time = time.time()\n",
    "    iteration_time = end_time - start_time\n",
    "    print( f\"Trained {x} clusters in {iteration_time} with score:  {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(testingsizes, scores, 'bo-', linewidth=2)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Elbow Graph for Agglomerative Clustering (Silhouette Score)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE.train_agglomerative(3)\n",
    "GSE.plot_clusters('agglomerative', '3 clusters for all companies weighed by number of orders')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per customer models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the specific sklearn warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names, but KMeans was fitted with feature names\")\n",
    "\n",
    "# Suppress the specific SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "# function that checks how many rows have a non zero value in the column devided by the total amount of rows\n",
    "def check_cluster_balance(df, column):\n",
    "    return df[df[column] != 0].shape[0] / df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE.set_verbose(False)\n",
    "\n",
    "results_dict = {}\n",
    "testsizes = list(range(1,150))\n",
    "\n",
    "for company in companies_list:\n",
    "    print(company)\n",
    "    print(\"====================================\")\n",
    "    \n",
    "    df_to_use = df_orders[df_orders['OPDRACHTGEVERNAAM'] == company]\n",
    "    unique_clusters = len(df_to_use[\"LOS_CPC\"].unique()) - 3\n",
    "    GSE.set_input_df(df_to_use)\n",
    "    GSE.clean_input_df()\n",
    "    \n",
    "    results_dict[company] = {}\n",
    "    for testsize in testsizes:\n",
    "        if testsize > unique_clusters:\n",
    "            break\n",
    "                \n",
    "        #kmeans palletplaasten\n",
    "        if \"kmeans_pallets\" not in results_dict[company]:\n",
    "                results_dict[company][\"kmeans_pallets\"] = {}\n",
    "\n",
    "        GSE.train_kmeans(testsize, \"PALLETPLAATSEN\")\n",
    "        df_condensed = GSE.condense_orders()\n",
    "        region_columns = [col for col in df_condensed.columns if col.startswith('REGION_')]\n",
    "        \n",
    "        for region_col in region_columns:\n",
    "            bal = check_cluster_balance(df_condensed, region_col)\n",
    "            if testsize not in results_dict[company][\"kmeans_pallets\"]:\n",
    "                results_dict[company][\"kmeans_pallets\"][testsize] = {}\n",
    "            results_dict[company][\"kmeans_pallets\"][testsize][region_col] = bal\n",
    "        mean_kmeans = np.mean([results_dict[company][\"kmeans_pallets\"][testsize][region_col] for region_col in region_columns])\n",
    "        print(f\"{testsize} clusters kmeans pallets mean balance: {mean_kmeans}\")\n",
    "\n",
    "        #kmeans ordercount\n",
    "        if \"kmeans_ordercount\" not in results_dict[company]:\n",
    "                results_dict[company][\"kmeans_ordercount\"] = {}\n",
    "\n",
    "        GSE.train_kmeans(testsize, \"SHIPMENT_COUNT\")\n",
    "        df_condensed = GSE.condense_orders()\n",
    "        region_columns = [col for col in df_condensed.columns if col.startswith('REGION_')]\n",
    "        \n",
    "        for region_col in region_columns:\n",
    "            bal = check_cluster_balance(df_condensed, region_col)\n",
    "            if testsize not in results_dict[company][\"kmeans_ordercount\"]:\n",
    "                results_dict[company][\"kmeans_ordercount\"][testsize] = {}\n",
    "            results_dict[company][\"kmeans_ordercount\"][testsize][region_col] = bal\n",
    "        mean_kmeans_pal = np.mean([results_dict[company][\"kmeans_ordercount\"][testsize][region_col] for region_col in region_columns])\n",
    "        print(f\"{testsize} clusters kmeans ordercount mean balance: {mean_kmeans_pal}\")\n",
    "\n",
    "        #hierarch\n",
    "        if \"hierarch\" not in results_dict[company]:\n",
    "                results_dict[company][\"hierarch\"] = {}\n",
    "\n",
    "        GSE.train_agglomerative(n_clusters = testsize)\n",
    "        df_condensed = GSE.condense_orders()\n",
    "        region_columns = [col for col in df_condensed.columns if col.startswith('REGION_')]\n",
    "        \n",
    "        for region_col in region_columns:\n",
    "            bal = check_cluster_balance(df_condensed, region_col)\n",
    "            if testsize not in results_dict[company][\"hierarch\"]:\n",
    "                results_dict[company][\"hierarch\"][testsize] = {}\n",
    "            results_dict[company][\"hierarch\"][testsize][region_col] = bal\n",
    "        mean_agg = np.mean([results_dict[company][\"hierarch\"][testsize][region_col] for region_col in region_columns])\n",
    "        print(f\"{testsize} clusters hierarch mean balance: {mean_agg}\")\n",
    "\n",
    "        if mean_kmeans < 0.2 and mean_agg < 0.2 and mean_kmeans_pal < 0.2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# # Writing to a JSON file\n",
    "# with open('modellenbalanceindividual.json', 'w') as file:\n",
    "#     json.dump(results_dict, file, indent=4)  # indent=4 is optional for pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('modellenbalanceindividual.json', 'r') as file:\n",
    "    results_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global model calculated per customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSE.set_verbose(False)\n",
    "\n",
    "results_dict2 = {}\n",
    "testsizes = list(range(1,250))\n",
    "\n",
    "df_to_use = df_orders\n",
    "GSE.set_input_df(df_to_use)\n",
    "GSE.clean_input_df()\n",
    "\n",
    "for testsize in testsizes:\n",
    "    print(testsize)\n",
    "    #kmeans palletplaasten\n",
    "    GSE.train_kmeans(testsize, \"PALLETPLAATSEN\")\n",
    "    df_condensed = GSE.condense_orders()\n",
    "    region_columns = [col for col in df_condensed.columns if col.startswith('REGION_')] \n",
    "\n",
    "    for company in companies_list:\n",
    "        if company not in results_dict2:\n",
    "            results_dict2[company] = {}\n",
    "        if \"kmeans_pallets\" not in results_dict2[company]:\n",
    "            results_dict2[company][\"kmeans_pallets\"] = {}\n",
    "        temp_df = df_condensed[df_condensed['OPDRACHTGEVERNAAM'] == company]\n",
    "        for region_col in region_columns:\n",
    "            bal = check_cluster_balance(temp_df, region_col)\n",
    "            if testsize not in results_dict2[company][\"kmeans_pallets\"]:\n",
    "                results_dict2[company][\"kmeans_pallets\"][testsize] = {}\n",
    "            results_dict2[company][\"kmeans_pallets\"][testsize][region_col] = bal\n",
    "        mean_kmeans = np.mean([results_dict2[company][\"kmeans_pallets\"][testsize][region_col] for region_col in region_columns])\n",
    "        print(f\"{company} clusters kmeans pallets mean balance: {mean_kmeans}\")\n",
    "\n",
    "\n",
    "    #kmeans ordercount\n",
    "    GSE.train_kmeans(testsize, \"SHIPMENT_COUNT\")\n",
    "    df_condensed = GSE.condense_orders()\n",
    "    region_columns = [col for col in df_condensed.columns if col.startswith('REGION_')]\n",
    "\n",
    "    for company in companies_list:\n",
    "        if \"kmeans_ordercount\" not in results_dict2[company]:\n",
    "            results_dict2[company][\"kmeans_ordercount\"] = {}\n",
    "        temp_df = df_condensed[df_condensed['OPDRACHTGEVERNAAM'] == company]\n",
    "        for region_col in region_columns:\n",
    "            bal = check_cluster_balance(temp_df, region_col)\n",
    "            if testsize not in results_dict2[company][\"kmeans_ordercount\"]:\n",
    "                results_dict2[company][\"kmeans_ordercount\"][testsize] = {}\n",
    "            results_dict2[company][\"kmeans_ordercount\"][testsize][region_col] = bal\n",
    "        mean_kmeans_pal = np.mean([results_dict2[company][\"kmeans_ordercount\"][testsize][region_col] for region_col in region_columns])\n",
    "        print(f\"{company} clusters kmeans ordercount mean balance: {mean_kmeans_pal}\")\n",
    "\n",
    "    \n",
    "    #hierarch\n",
    "    GSE.train_agglomerative(n_clusters = testsize)\n",
    "    df_condensed = GSE.condense_orders()\n",
    "    region_columns = [col for col in df_condensed.columns if col.startswith('REGION_')]\n",
    "    \n",
    "    for company in companies_list:\n",
    "        if \"hierarch\" not in results_dict2[company]:\n",
    "            results_dict2[company][\"hierarch\"] = {}\n",
    "        temp_df = df_condensed[df_condensed['OPDRACHTGEVERNAAM'] == company]\n",
    "        for region_col in region_columns:\n",
    "            bal = check_cluster_balance(temp_df, region_col)\n",
    "            if testsize not in results_dict2[company][\"hierarch\"]:\n",
    "                results_dict2[company][\"hierarch\"][testsize] = {}\n",
    "            results_dict2[company][\"hierarch\"][testsize][region_col] = bal\n",
    "        mean_agg = np.mean([results_dict2[company][\"hierarch\"][testsize][region_col] for region_col in region_columns])\n",
    "        print(f\"{company} clusters hierarch mean balance: {mean_agg}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# # Writing to a JSON file\n",
    "# with open('modellenbalancecommon_gse.json', 'w') as file:\n",
    "#     json.dump(results_dict2, file, indent=4)  # indent=4 is optional for pretty printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting of various statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from JSON file modellenbalancecommon_gse.json to results_dict2\n",
    "import json\n",
    "with open('modellenbalancecommon_gse.json', 'r') as file:\n",
    "    temp = json.load(file)\n",
    "results_dict2={}\n",
    "for x in temp:\n",
    "    results_dict2[x] ={}\n",
    "    for y in temp[x]:\n",
    "        results_dict2[x][y] = {}\n",
    "        for z in temp[x][y]:\n",
    "            results_dict2[x][y][int(z)] = temp[x][y][z]\n",
    "\n",
    "# Read from JSON file modellenbalanceindividual.json to results_dict\n",
    "with open('modellenbalanceindividual.json', 'r') as file:\n",
    "    temp = json.load(file)\n",
    "results_dict = {}\n",
    "for x in temp:\n",
    "    results_dict[x] ={}\n",
    "    for y in temp[x]:\n",
    "        results_dict[x][y] = {}\n",
    "        for z in temp[x][y]:\n",
    "            results_dict[x][y][int(z)] = temp[x][y][z]\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All companies with global model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(8, 6))\n",
    "for company in results_dict2:\n",
    "    companylist = []\n",
    "    testsizes = []\n",
    "    for testsize in results_dict2[company][\"hierarch\"]:\n",
    "        testsizes.append(testsize)\n",
    "        mean_agg = np.mean([results_dict2[company][\"hierarch\"][testsize][region_col] for region_col in results_dict2[company][\"hierarch\"][testsize]])\n",
    "        # print(f\"{testsize} clusters hierarch mean balance: {mean_agg}\")\n",
    "        companylist.append(mean_agg)\n",
    "        #plot the results\n",
    "    \n",
    "    plt.plot(testsizes, companylist, '-', linewidth=1)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Mean balance')\n",
    "plt.title(f'Balance of clusters with a global model (hierarchical)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All companies with individual models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(8, 6))\n",
    "for company in results_dict:\n",
    "    companylist = []\n",
    "    testsizes = []\n",
    "    for testsize in results_dict[company][\"hierarch\"]:\n",
    "        testsizes.append(testsize)\n",
    "        mean_agg = np.mean([results_dict[company][\"hierarch\"][testsize][region_col] for region_col in results_dict[company][\"hierarch\"][testsize]])\n",
    "        # print(f\"{testsize} clusters hierarch mean balance: {mean_agg}\")\n",
    "        companylist.append(mean_agg)\n",
    "        #plot the results\n",
    "    \n",
    "    plt.plot(testsizes, companylist, '-', linewidth=1)\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Mean balance')\n",
    "plt.title(f'Balance of clusters with company specific cluster models (hierarchical)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per company a graph for balance+variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "colordict = {0: {\"kmeans_pallets\": \"#1f77b4\", \"kmeans_ordercount\": \"#ff7f0e\", \"hierarch\": \"#2ca02c\"},\n",
    "             1: {\"kmeans_pallets\": \"#9467bd\", \"kmeans_ordercount\": \"#d62728\", \"hierarch\": \"#17becf\"}}\n",
    "for company in results_dict2:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for type in results_dict2[company]:\n",
    "        companylist = []\n",
    "        varlist = []\n",
    "        testsizes = []\n",
    "        for testsize in results_dict2[company][type]:\n",
    "            testsizes.append(testsize)\n",
    "            mean_agg = np.mean([results_dict2[company][type][testsize][region_col] for region_col in results_dict2[company][type][testsize]])\n",
    "            variability_agg = np.std([results_dict2[company][type][testsize][region_col] for region_col in results_dict2[company][type][testsize]])\n",
    "            # print(f\"{testsize} clusters hierarch mean balance: {mean_agg}\")\n",
    "            companylist.append(mean_agg)\n",
    "            varlist.append(variability_agg)\n",
    "            #plot the results\n",
    "        plt.plot(testsizes, companylist, '-',color=colordict[0][type], linewidth=2, label=f\"individual_{type}\")\n",
    "        # plt.plot(testsizes, varlist, '--', color=colordict[0][type], linewidth=2, label=f\"individual_{type}_var\")\n",
    "    \n",
    "    for type in results_dict[company]:\n",
    "        companylist = []\n",
    "        varlist = []\n",
    "        testsizes = []\n",
    "        for testsize in results_dict[company][type]:\n",
    "            testsizes.append(testsize)\n",
    "            mean_agg = np.mean([results_dict[company][type][testsize][region_col] for region_col in results_dict[company][type][testsize]])\n",
    "            variability_agg = np.std([results_dict[company][type][testsize][region_col] for region_col in results_dict[company][type][testsize]])\n",
    "            # print(f\"{testsize} clusters hierarch mean balance: {mean_agg}\")\n",
    "            companylist.append(mean_agg)\n",
    "            varlist.append(variability_agg)\n",
    "            #plot the results\n",
    "        plt.plot(testsizes, companylist, '-', color=colordict[1][type], linewidth=2, label=f\"common_{type}\")\n",
    "        # plt.plot(testsizes, varlist, '--', color=colordict[1][type], linewidth=2, label=f\"common_{type}_var\")\n",
    "   \n",
    "\n",
    "\n",
    "    plt.xlabel('Number of clusters (k)', fontsize=14)\n",
    "    plt.ylabel('Mean balance', fontsize=14)\n",
    "    plt.xlim(0, 150)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    name = final_dict[company]['fakename']\n",
    "    plt.title(f'Balance-score against number of clusters with various \\n clustering models for {final_dict[company][\"fakename\"]}', fontsize=16)\n",
    "    legendlist = ['Per Company Model-KMeans Weighed By Pallets', 'Per Company Model-KMeans Weighed By Order Count', 'Per Company Model-Hierarchical', 'Global Model-KMeans Weighed By Pallets', 'Global Model-KMeans Weighed By Order Count', 'Global Model-Hierarchical']\n",
    "    plt.legend(legendlist,fontsize=12)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single graph with mean model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries to store aggregated values\n",
    "aggregated_results_dict2 = {}\n",
    "aggregated_results_dict = {}\n",
    "\n",
    "# Initialize the dictionaries\n",
    "for company in results_dict2:\n",
    "    for type in results_dict2[company]:\n",
    "        if type not in aggregated_results_dict2:\n",
    "            aggregated_results_dict2[type] = {}\n",
    "        for testsize in results_dict2[company][type]:\n",
    "            if testsize not in aggregated_results_dict2[type]:\n",
    "                aggregated_results_dict2[type][testsize] = []\n",
    "\n",
    "for company in results_dict:\n",
    "    for type in results_dict[company]:\n",
    "        if type not in aggregated_results_dict:\n",
    "            aggregated_results_dict[type] = {}\n",
    "        for testsize in results_dict[company][type]:\n",
    "            if testsize not in aggregated_results_dict[type]:\n",
    "                aggregated_results_dict[type][testsize] = []\n",
    "\n",
    "# Accumulate values for each type and testsize across all companies\n",
    "for company in results_dict2:\n",
    "    for type in results_dict2[company]:\n",
    "        for testsize in results_dict2[company][type]:\n",
    "            mean_agg = np.mean([results_dict2[company][type][testsize][region_col] for region_col in results_dict2[company][type][testsize]])\n",
    "            aggregated_results_dict2[type][testsize].append(mean_agg)\n",
    "\n",
    "for company in results_dict:\n",
    "    for type in results_dict[company]:\n",
    "        for testsize in results_dict[company][type]:\n",
    "            mean_agg = np.mean([results_dict[company][type][testsize][region_col] for region_col in results_dict[company][type][testsize]])\n",
    "            aggregated_results_dict[type][testsize].append(mean_agg)\n",
    "\n",
    "# Create a single plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot the aggregated mean values\n",
    "for type in aggregated_results_dict2:\n",
    "    testsizes = sorted(aggregated_results_dict2[type].keys())\n",
    "    mean_values = [np.mean(aggregated_results_dict2[type][testsize]) for testsize in testsizes]\n",
    "    plt.plot(testsizes, mean_values, '-', linewidth=2, label=f\"individual_{type}\")\n",
    "\n",
    "\n",
    "for type in aggregated_results_dict:\n",
    "    testsizes = sorted(aggregated_results_dict[type].keys())\n",
    "    mean_values = [np.mean(aggregated_results_dict[type][testsize]) for testsize in testsizes]\n",
    "    plt.plot(testsizes, mean_values, '--', linewidth=2, label=f\"common_{type}\")\n",
    "\n",
    "plt.xlabel('Number of clusters (k)', fontsize=14)\n",
    "plt.ylabel('Mean balance', fontsize=14)\n",
    "plt.xlim(0, 150)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title('Balance of clusters with various cluster models (Aggregated)', fontsize=16)\n",
    "legendlist = ['Per Company Model-KMeans Weighed By Pallets', 'Per Company Model-KMeans Weighed By Order Count', 'Per Company Model-Hierarchical', 'Global Model-KMeans Weighed By Pallets', 'Global Model-KMeans Weighed By Order Count', 'Global Model-Hierarchical']\n",
    "\n",
    "plt.legend(legendlist,fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common\n",
    "print(\"global\")\n",
    "for model in aggregated_results_dict2:\n",
    "    for size in aggregated_results_dict2[model]:\n",
    "        avg = np.mean(aggregated_results_dict2[model][size])\n",
    "        if avg < 0.5:\n",
    "            break\n",
    "    print(f\"model: {model}, size: {size}, mean: {np.mean(aggregated_results_dict2[model][size])}\")\n",
    "\n",
    "# individual\n",
    "print(\"individual\")\n",
    "for model in aggregated_results_dict:\n",
    "    for size in aggregated_results_dict[model]:\n",
    "        avg = np.mean(aggregated_results_dict[model][size])\n",
    "        if avg < 0.5:\n",
    "            break\n",
    "    print(f\"model: {model}, size: {size}, mean: {np.mean(aggregated_results_dict[model][size])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per company two graphs for balance and std (anonimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "\n",
    "# Color dictionary\n",
    "colordict = {0: {\"kmeans_pallets\": \"#1f77b4\", \"kmeans_ordercount\": \"#ff7f0e\", \"hierarch\": \"#2ca02c\"},\n",
    "             1: {\"kmeans_pallets\": \"#9467bd\", \"kmeans_ordercount\": \"#d62728\", \"hierarch\": \"#17becf\"}}\n",
    "\n",
    "# List of alphabet letters to use for company labels\n",
    "company_labels = list(string.ascii_uppercase)\n",
    "\n",
    "# Counter for companies\n",
    "company_counter = 0\n",
    "\n",
    "for company in results_dict2:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    for type in results_dict2[company]:\n",
    "        companylist = []\n",
    "        varlist = []\n",
    "        testsizes = []\n",
    "        for testsize in results_dict2[company][type]:\n",
    "            testsizes.append(testsize)\n",
    "            mean_agg = np.mean([results_dict2[company][type][testsize][region_col] for region_col in results_dict2[company][type][testsize]])\n",
    "            variability_agg = np.std([results_dict2[company][type][testsize][region_col] for region_col in results_dict2[company][type][testsize]])\n",
    "            companylist.append(mean_agg)\n",
    "            varlist.append(variability_agg)\n",
    "        \n",
    "        # Plot the balance results on the left subplot\n",
    "        axes[0].plot(testsizes, companylist, '-', color=colordict[0][type], linewidth=2, label=f\"individual_{type}\")\n",
    "        # Plot the variability results on the right subplot\n",
    "        axes[1].plot(testsizes, varlist, '-', color=colordict[0][type], linewidth=2, label=f\"individual_{type}_var\")\n",
    "    \n",
    "    for type in results_dict[company]:\n",
    "        companylist = []\n",
    "        varlist = []\n",
    "        testsizes = []\n",
    "        for testsize in results_dict[company][type]:\n",
    "            testsizes.append(testsize)\n",
    "            mean_agg = np.mean([results_dict[company][type][testsize][region_col] for region_col in results_dict[company][type][testsize]])\n",
    "            variability_agg = np.std([results_dict[company][type][testsize][region_col] for region_col in results_dict[company][type][testsize]])\n",
    "            companylist.append(mean_agg)\n",
    "            varlist.append(variability_agg)\n",
    "        \n",
    "        # Plot the balance results on the left subplot\n",
    "        axes[0].plot(testsizes, companylist, '--', color=colordict[0][type], linewidth=2, label=f\"common_{type}\")\n",
    "        # Plot the variability results on the right subplot\n",
    "        axes[1].plot(testsizes, varlist, '--', color=colordict[0][type], linewidth=2, label=f\"common_{type}_var\")\n",
    "\n",
    "    # Use the company_counter to get the label\n",
    "    company_label = company_labels[company_counter % len(company_labels)]\n",
    "    company_counter += 1\n",
    "\n",
    "    # Labeling and formatting for the left subplot\n",
    "    axes[0].set_xlabel('Number of clusters (k)')\n",
    "    axes[0].set_ylabel('Mean balance')\n",
    "    axes[0].set_xlim(0, 150)\n",
    "    axes[0].set_title(f'Balance of clusters for Company {company_label}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Labeling and formatting for the right subplot\n",
    "    axes[1].set_xlabel('Number of clusters (k)')\n",
    "    axes[1].set_ylabel('Standard Deviation')\n",
    "    axes[1].set_xlim(0, 150)\n",
    "    axes[1].set_title(f'Variability of clusters for Company {company_label}')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two graphs for all companies model Balance and STD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color dictionary\n",
    "colordict = {0: {\"kmeans_pallets\": \"#1f77b4\", \"kmeans_ordercount\": \"#ff7f0e\", \"hierarch\": \"#2ca02c\"},\n",
    "             1: {\"kmeans_pallets\": \"#9467bd\", \"kmeans_ordercount\": \"#d62728\", \"hierarch\": \"#17becf\"}}\n",
    "\n",
    "# Create dictionaries to store aggregated values\n",
    "aggregated_means_dict2 = {}\n",
    "aggregated_stds_dict2 = {}\n",
    "aggregated_means_dict = {}\n",
    "aggregated_stds_dict = {}\n",
    "\n",
    "# Initialize the dictionaries\n",
    "for company in results_dict2:\n",
    "    for type in results_dict2[company]:\n",
    "        if type not in aggregated_means_dict2:\n",
    "            aggregated_means_dict2[type] = {}\n",
    "            aggregated_stds_dict2[type] = {}\n",
    "        for testsize in results_dict2[company][type]:\n",
    "            if testsize not in aggregated_means_dict2[type]:\n",
    "                aggregated_means_dict2[type][testsize] = []\n",
    "                aggregated_stds_dict2[type][testsize] = []\n",
    "\n",
    "for company in results_dict:\n",
    "    for type in results_dict[company]:\n",
    "        if type not in aggregated_means_dict:\n",
    "            aggregated_means_dict[type] = {}\n",
    "            aggregated_stds_dict[type] = {}\n",
    "        for testsize in results_dict[company][type]:\n",
    "            if testsize not in aggregated_means_dict[type]:\n",
    "                aggregated_means_dict[type][testsize] = []\n",
    "                aggregated_stds_dict[type][testsize] = []\n",
    "\n",
    "# Accumulate values for each type and testsize across all companies\n",
    "for company in results_dict2:\n",
    "    for type in results_dict2[company]:\n",
    "        for testsize in results_dict2[company][type]:\n",
    "            mean_agg = np.mean([results_dict2[company][type][testsize][region_col] for region_col in results_dict2[company][type][testsize]])\n",
    "            std_agg = np.std([results_dict2[company][type][testsize][region_col] for region_col in results_dict2[company][type][testsize]])\n",
    "            aggregated_means_dict2[type][testsize].append(mean_agg)\n",
    "            aggregated_stds_dict2[type][testsize].append(std_agg)\n",
    "\n",
    "for company in results_dict:\n",
    "    for type in results_dict[company]:\n",
    "        for testsize in results_dict[company][type]:\n",
    "            mean_agg = np.mean([results_dict[company][type][testsize][region_col] for region_col in results_dict[company][type][testsize]])\n",
    "            std_agg = np.std([results_dict[company][type][testsize][region_col] for region_col in results_dict[company][type][testsize]])\n",
    "            aggregated_means_dict[type][testsize].append(mean_agg)\n",
    "            aggregated_stds_dict[type][testsize].append(std_agg)\n",
    "\n",
    "# Create a single figure with two subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot the aggregated mean values on the left subplot\n",
    "for type in aggregated_means_dict2:\n",
    "    testsizes = sorted(aggregated_means_dict2[type].keys())\n",
    "    mean_values = [np.mean(aggregated_means_dict2[type][testsize]) for testsize in testsizes]\n",
    "    axes[0].plot(testsizes, mean_values, '-', linewidth=2, color=colordict[0][type], label=f\"individual_{type}\")\n",
    "\n",
    "for type in aggregated_means_dict:\n",
    "    testsizes = sorted(aggregated_means_dict[type].keys())\n",
    "    mean_values = [np.mean(aggregated_means_dict[type][testsize]) for testsize in testsizes]\n",
    "    axes[0].plot(testsizes, mean_values, '--', linewidth=2, color=colordict[1][type], label=f\"common_{type}\")\n",
    "\n",
    "axes[0].set_xlabel('Number of clusters (k)')\n",
    "axes[0].set_ylabel('Mean balance in clusters')\n",
    "axes[0].set_xlim(0, 150)\n",
    "axes[0].set_title('Mean Balance in clusters for all companies')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot the aggregated standard deviation values on the right subplot\n",
    "for x in aggregated_stds_dict2:\n",
    "    testsizes = sorted(aggregated_stds_dict2[x].keys())\n",
    "    std_values = [np.mean(aggregated_stds_dict2[x][testsize]) for testsize in testsizes]\n",
    "    axes[1].plot(testsizes, std_values, '-', linewidth=2, color=colordict[0][x], label=f\"individual_{x}_var\")\n",
    "\n",
    "for x in aggregated_stds_dict:\n",
    "    testsizes = sorted(aggregated_stds_dict[x].keys())\n",
    "    std_values = [np.mean(aggregated_stds_dict[x][testsize]) for testsize in testsizes]\n",
    "    axes[1].plot(testsizes, std_values, '--', linewidth=2, color=colordict[1][x], label=f\"common_{x}_var\")\n",
    "\n",
    "axes[1].set_xlabel('Number of clusters (k)')\n",
    "axes[1].set_ylabel('Standard Deviation in cluster balance')\n",
    "axes[1].set_xlim(0, 150)\n",
    "axes[1].set_title('Aggregated Standard Deviation for all Companies')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define definitive number of clusters for companies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import custom.GeoSpatialEncoder\n",
    "final_dict = {}\n",
    "\n",
    "def generate_company_labels(num_companies):\n",
    "    company_labels = list(string.ascii_uppercase)\n",
    "    extended_labels = []\n",
    "\n",
    "    # Generate single-letter labels\n",
    "    for letter in company_labels:\n",
    "        extended_labels.append(letter)\n",
    "    \n",
    "    # Generate double-letter labels\n",
    "    for first_letter in company_labels:\n",
    "        for second_letter in company_labels:\n",
    "            extended_labels.append(first_letter + second_letter)\n",
    "    \n",
    "    # Return the first 'num_companies' labels\n",
    "    return extended_labels[:num_companies]\n",
    "\n",
    "company_labels = generate_company_labels(len(companies_list))\n",
    "    \n",
    "\n",
    "for i, company in enumerate(companies_list):\n",
    "    company_label = \"Company \"+ company_labels[i]\n",
    "    final_dict[company] = {}\n",
    "    df_to_use = df_orders[(df_orders['OPDRACHTGEVERNAAM'] == company) & (df_orders['AFHCODE'] == 'd')]\n",
    "    # find the highest number of clusters for each company in dictionary where the mean is above 0.5\n",
    "    for n in range(1, 250):\n",
    "        mean_agg = np.mean([results_dict2[company]['kmeans_ordercount'][n][region] for region in results_dict2[company]['kmeans_ordercount'][n]])\n",
    "        if mean_agg < 0.5:\n",
    "            break\n",
    "    print(f\"Company: {company}, Number of clusters: {n}\")\n",
    "    final_dict[company][\"nclusters\"] = n\n",
    "    final_dict[company][\"fakename\"] = company_label\n",
    "    final_dict[company][\"model\"] = GeoSpatialEncoder(PC_obj)\n",
    "    final_dict[company][\"model\"].set_verbose(False)\n",
    "    final_dict[company][\"model\"].set_input_df(df_to_use)\n",
    "    final_dict[company][\"model\"].clean_input_df()\n",
    "    final_dict[company][\"model\"].train_kmeans(n, 'SHIPMENT_COUNT')\n",
    "    final_dict[company][\"CPC_dict\"] = final_dict[company]['model'].kmeans_dict\n",
    "\n",
    "    print(f\"Model trained for {company_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[company].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dict = {}\n",
    "for i, company in enumerate(companies_list):\n",
    "    temp_dict[company] = []\n",
    "    for model in results_dict2[company]:\n",
    "        for testsize in results_dict2[company][model]:\n",
    "            mean_agg = np.mean([results_dict2[company][model][testsize][region] for region in results_dict2[company][model][testsize]])\n",
    "            if mean_agg < 0.5:\n",
    "                break\n",
    "        temp_dict[company].append(testsize)\n",
    "\n",
    "position_counts = {1: 0, 2: 0, 3: 0}    \n",
    "for company, values in temp_dict.items():\n",
    "    max_value = max(values)\n",
    "    for i, value in enumerate(values):\n",
    "        if value == max_value:\n",
    "            position_counts[i + 1] += 1\n",
    "\n",
    "position_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove GSE object from dictionary:\n",
    "# final_dict_export = {}\n",
    "# for company in companies_list:\n",
    "#     final_dict_export[company] = final_dict[company].copy()\n",
    "#     final_dict_export[company].pop('model', None)\n",
    "\n",
    "\n",
    "# # save final_dict to a json file\n",
    "# import json\n",
    "# with open('clusters_final_dict.json', 'w') as file:\n",
    "#     json.dump(final_dict_export, file, indent=4)  # indent=4 is optional for pretty printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read final_dict from json file\n",
    "import json\n",
    "with open('clusters_final_dict.json', 'r') as file:\n",
    "    final_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for each company the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in final_dict:\n",
    "    print(f\"Company: {company}, Number of clusters: {final_dict[company]['nclusters']}\")\n",
    "    df_to_use = df_orders[(df_orders['OPDRACHTGEVERNAAM'] == company) & (df_orders['AFHCODE'] == 'd')]\n",
    "    final_dict[company][\"model\"] = GeoSpatialEncoder(PC_obj)\n",
    "    final_dict[company][\"model\"].set_verbose(False)\n",
    "    final_dict[company][\"model\"].set_input_df(df_to_use)\n",
    "    final_dict[company][\"model\"].clean_input_df()\n",
    "    final_dict[company][\"model\"].train_kmeans(final_dict[company]['nclusters'], 'SHIPMENT_COUNT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "for company in companies_list:\n",
    "    fakename = final_dict[company][\"fakename\"]\n",
    "    df_plot = final_dict[company][\"model\"].df_CPC_kmeans.groupby('LOS_CPC').agg({'PALLETPLAATSEN': 'first', \n",
    "                                                                   'LOS_LAT': 'first', \n",
    "                                                                   'LOS_LON': 'first',\n",
    "                                                                   'COORDINATES': 'first',\n",
    "                                                                   'CLUSTER': 'first'}).reset_index()\n",
    "    cluster_info = final_dict[company][\"model\"].return_cluster_kmeans_info()\n",
    "    n_clusters = final_dict[company][\"model\"].kmeans_n_clusters\n",
    "\n",
    "    # Plot the base map with the outlines of the countries\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    final_dict[company][\"model\"].countries.boundary.plot(ax=ax, linewidth=1, edgecolor='black')\n",
    "\n",
    "    # Plot the clusters\n",
    "    sns.scatterplot(x=\"LOS_LON\", y=\"LOS_LAT\", hue=\"CLUSTER\", data=df_plot, palette=\"tab20\", ax=ax, legend=False)\n",
    "\n",
    "    for i, center in cluster_info.iterrows():\n",
    "        ax.plot(center['LOS_LON'], center['LOS_LAT'], 'r+', markersize=10)\n",
    "    plt.title(f\"{n_clusters} clusters for {fakename}\", fontsize=16)\n",
    "    plt.xlabel(\"Longitude\", fontsize=14)\n",
    "    plt.ylabel(\"Latitude\", fontsize=14)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    # Custom legend\n",
    "    cluster_center = mlines.Line2D([], [], color='red', marker='+', linestyle='None', markersize=10, label='Cluster Center')\n",
    "    delivery_location = mlines.Line2D([], [], color='grey', marker='o', linestyle='None', markersize=10, label='Delivery Location')\n",
    "    plt.legend(handles=[cluster_center, delivery_location], fontsize=12, loc='upper left')\n",
    "\n",
    "\n",
    "    ax.set_xticks(np.arange(3, 8, 1))\n",
    "    ax.set_yticks(np.arange(50, 54, 1))\n",
    "\n",
    "    plt.savefig(f\"FILEPATH HERE\", bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies_list:\n",
    "    print(f\"Company: {company}\")\n",
    "    print(\"====================================\")\n",
    "    final_dict[company]['model'].plot_clusters(\"kmeans\", f\"{final_dict[company]['nclusters']} clusters for {final_dict[company]['fakename']}\",\n",
    "                                               f\"FILEPATH HERE\")\n",
    "    print(f\"Number of clusters: {final_dict[company]['nclusters']}\")\n",
    "    print(f\"Fake name: {final_dict[company]['fakename']}\")\n",
    "    print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[\"HUSK_MEDICAL_BV\"][\"kmeans_ordercount\"][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict2[\"HUSK_MEDICAL_BV\"][\"kmeans_ordercount\"][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies_list:\n",
    "\n",
    "final_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solver-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
