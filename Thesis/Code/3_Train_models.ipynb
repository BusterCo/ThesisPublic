{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from datetime import time, timedelta\n",
    "from custom.GeoSpatialEncoder import GeoSpatialEncoder\n",
    "from custom.PC_Class import PC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"seaborn\")\n",
    "\n",
    "def load_data(file_path):\n",
    "    datetime_cols = ['CREATIONDATETIME', 'LAAD_DATETIME_VAN', 'LAAD_DATETIME_TOT', 'LOS_DATETIME_VAN', 'LOS_DATETIME_TOT', '15CREATIONDATETIME']\n",
    "    total_rows = sum(1 for row in open(file_path, 'r', encoding='utf-8'))\n",
    "    chunk_size = 10000  \n",
    "    tqdm.pandas(desc=\"Reading CSV\")\n",
    "    chunks = pd.read_csv(file_path, chunksize=chunk_size, iterator=True, index_col = 0, parse_dates=datetime_cols)\n",
    "\n",
    "    df_orders = pd.concat(tqdm(chunks, total=total_rows//chunk_size))\n",
    "    print(\"Lenght of input data:\", str(len(df_orders)))\n",
    "    return df_orders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct = os.getcwd()\n",
    "file_path = direct + \"////data////vos_input_data////MultiHubData3_training.csv\" \n",
    "PC_obj = PC()\n",
    "print(\"PC object created\")\n",
    "df_orders  = load_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load companies information from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the final_dict from file\n",
    "import json\n",
    "with open('clusters_final_dict.json', 'r') as file:\n",
    "    clusters_dict = json.load(file)\n",
    "\n",
    "for company in clusters_dict:\n",
    "    print(company)\n",
    "    df_to_use = df_orders[(df_orders['OPDRACHTGEVERNAAM'] == company)]\n",
    "    clusters_dict[company][\"model\"] = GeoSpatialEncoder(PC_obj)\n",
    "    clusters_dict[company][\"model\"].set_verbose(False)\n",
    "    clusters_dict[company][\"model\"].set_input_df(df_to_use)\n",
    "    clusters_dict[company][\"model\"].clean_input_df()\n",
    "    clusters_dict[company][\"model\"].train_kmeans(clusters_dict[company]['nclusters'], 'SHIPMENT_COUNT')\n",
    "    # clusters_dict[company][\"CPC_dict2\"] = clusters_dict[company]['model'].kmeans_dict\n",
    "    # equal = clusters_dict[company][\"CPC_dict2\"] == clusters_dict[company][\"CPC_dict\"]\n",
    "    # print(f\"Loaded dict equals saved dict: {equal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscelaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_and_scaled_columns(df_to_use):\n",
    "    region_columns = [col for col in df_to_use.columns if col.startswith('REGION_')]\n",
    "    \n",
    "    # Calculate binary and scaled columns\n",
    "    bin_columns = df_to_use[region_columns].gt(0).astype(int)\n",
    "    bin_columns.columns = [\"BIN_\" + col for col in region_columns]\n",
    "    \n",
    "    scaled_columns = df_to_use[region_columns]#.div(df_to_use['PALLETPLAATSEN_ACTUAL'], axis=0) # <-------------------------------------------------------------------------\n",
    "    scaled_columns.columns = [\"SCALED_\" + col for col in region_columns]\n",
    "    \n",
    "    # Concatenate original df with new binary and scaled columns\n",
    "    df_to_use = pd.concat([df_to_use, bin_columns, scaled_columns], axis=1)\n",
    "    \n",
    "    # Filter out the columns where the total is 0\n",
    "    totals = df_to_use[region_columns].sum()\n",
    "    zero_regions = totals[totals == 0].index.tolist()\n",
    "    \n",
    "    # Drop columns corresponding to zero regions\n",
    "    drop_columns = zero_regions + [\"BIN_\" + col for col in zero_regions] + [\"SCALED_\" + col for col in zero_regions]\n",
    "    df_to_use.drop(columns=drop_columns, inplace=True)\n",
    "    \n",
    "    print(f\"Removed {len(zero_regions)} regions with no demand\")\n",
    "    return df_to_use\n",
    "\n",
    "\n",
    "def filter_train_test_split(df_to_use):\n",
    "    df_to_use = df_to_use.copy()\n",
    "    categorical_features = ['LAADPC', 'dayofweekcreation', 'weeknr']\n",
    "    continuous_features = ['PALLETPLAATSEN', 'AANTALORDERS']\n",
    "    features = categorical_features + continuous_features\n",
    "    region_columns = [col for col in df_to_use.columns if col.startswith('REGION_')]\n",
    "    non_region_columns = [col for col in df_to_use.columns if not col.startswith('REGION_')]\n",
    "\n",
    "    df_to_use = create_binary_and_scaled_columns(df_to_use)\n",
    "    # Encode and scale the entire dataset\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the encoder and scaler on the entire data\n",
    "    encoded_categorical_features = encoder.fit_transform(df_to_use[categorical_features])\n",
    "    scaled_continuous_features = scaler.fit_transform(df_to_use[continuous_features])\n",
    "\n",
    "    # Combine encoded and scaled features with the original DataFrame\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_features)\n",
    "    scaled_feature_names = scaler.get_feature_names_out(continuous_features)\n",
    "    feature_names = np.concatenate([encoded_feature_names, scaled_feature_names])\n",
    "\n",
    "    # Create DataFrames for encoded and scaled features\n",
    "    df_encoded = pd.DataFrame(encoded_categorical_features, columns=encoded_feature_names, index=df_to_use.index)\n",
    "    df_scaled = pd.DataFrame(scaled_continuous_features, columns=continuous_features, index=df_to_use.index)\n",
    "\n",
    "    # Concatenate the encoded and scaled features with the rest of the DataFrame\n",
    "    df_processed = pd.concat([df_to_use.drop(columns=categorical_features + continuous_features), df_encoded, df_scaled], axis=1)\n",
    "\n",
    "    # Split the DataFrame into train and test sets\n",
    "    train_df, test_df = train_test_split(df_processed, test_size=0.2, random_state=42)\n",
    "\n",
    "    feature_names # feature names used for training both models\n",
    "    classification_targets = [col for col in df_to_use.columns if col.startswith('BIN_REGION_')] # targets for classification model\n",
    "    regression_targets = [col for col in df_to_use.columns if col.startswith('SCALED_REGION_')] # targets for regression model\n",
    "\n",
    "    # Create the classification feature sets\n",
    "    X_train_class = train_df[feature_names]\n",
    "    Y_train_class = train_df[classification_targets]\n",
    "    X_test_class = test_df[feature_names]\n",
    "    Y_test_class = test_df[classification_targets]\n",
    "\n",
    "    # Create the regression feature sets\n",
    "    X_train_reg = train_df[list(feature_names) + classification_targets]\n",
    "    Y_train_reg = train_df[regression_targets]\n",
    "    X_test_reg = test_df[list(feature_names) + classification_targets]\n",
    "    Y_test_reg = test_df[regression_targets]\n",
    "\n",
    "    return X_train_class, Y_train_class, X_test_class, Y_test_class, X_train_reg, Y_train_reg, X_test_reg, Y_test_reg, scaler, encoder\n",
    "\n",
    "def softmax_with_zeros(x):\n",
    "    e_x = np.zeros_like(x, dtype=float)\n",
    "    non_zero_indices = x != 0\n",
    "    if np.any(non_zero_indices):\n",
    "        e_x[non_zero_indices] = np.exp(x[non_zero_indices] - np.max(x[non_zero_indices]))\n",
    "        e_x[non_zero_indices] = e_x[non_zero_indices] / e_x[non_zero_indices].sum()\n",
    "    return pd.Series(e_x, index=x.index)\n",
    "\n",
    "def eval_output(Y_test, Y_pred, company, model_name, extra_info=\"\"):\n",
    "    #Y_pred = Y_pred.abs()\n",
    "    mse = mean_squared_error(Y_test, Y_pred, multioutput='uniform_average')\n",
    "    mae = mean_absolute_error(Y_test, Y_pred)\n",
    "    r2 = r2_score(Y_test, Y_pred)\n",
    "\n",
    "    print(f'Metrics for {company} with {model_name} {extra_info}:')\n",
    "    print(f'Mean Squared Error: {mse}')\n",
    "    print(f'Mean Absolute Error: {mae}')\n",
    "    print(f'R-squared: {r2}')\n",
    "    print(\"\\n\")\n",
    "    return {\"MSE\": mse,\n",
    "            \"MAE\": mae, \n",
    "            \"R2\": r2}\n",
    "\n",
    "def get_binary_columns(df):\n",
    "    bin_columns = [col for col in df.columns if col.startswith('BIN_REGION_')]\n",
    "    return df[bin_columns]\n",
    "\n",
    "\n",
    "def filter_by_binary(predicteddf, testdf, binarydf):\n",
    "    \"\"\"\n",
    "    Filter the predicted and test dataframes by the binary dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    - predicteddf: DataFrame of predicted values\n",
    "    - testdf: DataFrame of true values\n",
    "    - binarydf: DataFrame of binary values (1 or 0)\n",
    "    \n",
    "    Returns:\n",
    "    - Filtered predicted and test arrays\n",
    "    \"\"\"\n",
    "    assert predicteddf.shape == testdf.shape == binarydf.shape, \"All input DataFrames must have the same shape\"\n",
    "\n",
    "    predicteddf.reset_index(drop=True, inplace=True)\n",
    "    testdf.reset_index(drop=True, inplace=True)\n",
    "    binarydf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    predicteddf.columns = testdf.columns\n",
    "    binarydf.columns = testdf.columns\n",
    "    \n",
    "    filtered_predicted = []\n",
    "    filtered_test = []\n",
    "    \n",
    "    # Iterate over each row\n",
    "    for i in range(len(binarydf)):\n",
    "        mask = binarydf.iloc[i] == 1\n",
    "        filtered_predicted.extend(predicteddf.iloc[i][mask].values)\n",
    "        filtered_test.extend(testdf.iloc[i][mask].values)\n",
    "    \n",
    "    return np.array(filtered_predicted), np.array(filtered_test)\n",
    "\n",
    "def create_dirty_data(X_test_reg, Y_pred_class):\n",
    "    columns_to_replace = [col for col in X_test_reg.columns if col.startswith('BIN_REGION_')]\n",
    "    Y_pred_class.columns = columns_to_replace\n",
    "    X_test_reg_dirty = X_test_reg.copy()\n",
    "    X_test_reg_dirty.reset_index(inplace=True, drop=True)\n",
    "    X_test_reg_dirty.drop(columns=columns_to_replace, inplace=True)\n",
    "    X_test_reg_dirty = pd.concat([X_test_reg_dirty, Y_pred_class], axis=1)\n",
    "    return X_test_reg_dirty\n",
    "\n",
    "def evaluate_model(X_train, X_test, Y_train, Y_test, model, model_name):\n",
    "    if model_name == 'AdaBoost':\n",
    "        Y_pred_aggregate = np.array([model.fit(X_train, Y_train[target]).predict(X_test) for target in Y_train.columns]).T\n",
    "        Y_pred_df = pd.DataFrame(Y_pred_aggregate, columns=Y_train.columns)\n",
    "    else:\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_pred_df = pd.DataFrame(model.predict(X_test), columns=Y_test.columns)\n",
    "    zerodiv = 1\n",
    "    accuracy = accuracy_score(Y_test.values.flatten(), Y_pred_df.values.flatten())\n",
    "    precision = precision_score(Y_test.values, Y_pred_df.values, average='macro', zero_division=zerodiv)\n",
    "    recall = recall_score(Y_test.values, Y_pred_df.values, average='macro', zero_division=zerodiv)\n",
    "    f1 = f1_score(Y_test.values, Y_pred_df.values, average='macro', zero_division=zerodiv)\n",
    "\n",
    "    print(f'Metrics for {company} with {model_name}:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 Score: {f1}')\n",
    "    print(\"\\n\")\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import re\n",
    "# Suppress the specific sklearn warning\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names, but KMeans was fitted with feature names\")\n",
    "\n",
    "# Suppress the specific SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "# Suppress specific FutureWarnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"DataFrame.applymap has been deprecated. Use DataFrame.map instead.\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\"The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\")\n",
    "# Suppress specific FutureWarnings related to SAMME.R algorithm deprecation\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=re.escape(\"The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict = {}\n",
    "\n",
    "categorical_features = ['LAADPC', 'dayofweekcreation', 'weeknr']\n",
    "continuous_features = ['PALLETPLAATSEN', 'AANTALORDERS']\n",
    "features = categorical_features + continuous_features\n",
    "for company in clusters_dict:\n",
    "    classifier_dict[company] = {}\n",
    "    print(f\"Processing {company}\")\n",
    "    df_condensed = clusters_dict[company][\"model\"].condense_orders()   \n",
    "    df_condensed[\"weeknr\"] = df_condensed[\"CREATIONDATETIME\"].dt.strftime(\"%V\")\n",
    "    region_columns = [col for col in df_condensed.columns if col.startswith('REGION_')]\n",
    "        \n",
    "    # Filter data for the specific company\n",
    "    df_to_use = df_condensed[df_condensed[\"OPDRACHTGEVERNAAM\"] == company]\n",
    "\n",
    "    # Calculate the totals for each region column and aquire targets\n",
    "    totals = df_to_use[region_columns].sum()\n",
    "    non_zero_totals = totals[totals != 0]\n",
    "    targets = list(non_zero_totals.keys())\n",
    "\n",
    "    df_to_use = df_to_use[features + targets]\n",
    "\n",
    "    # Prepare the feature matrix and target matrix\n",
    "    X = df_to_use[features]\n",
    "    Y = df_to_use[targets]\n",
    "\n",
    "    # Convert target values to binary (0 = False, 1 = True)\n",
    "    Y_binary = Y.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    # Handling categorical variables\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_categorical_features = encoder.fit_transform(df_to_use[categorical_features])\n",
    "\n",
    "    # Scale continuous variables\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_continuous_features = scaler.fit_transform(df_to_use[continuous_features])\n",
    "\n",
    "    # Combine all features\n",
    "    X_formatted = np.hstack([scaled_continuous_features, encoded_categorical_features])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_formatted, Y_binary, test_size=0.2, random_state=41)\n",
    "\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(random_state=42, n_estimators=300, min_samples_split=2, min_samples_leaf=1, max_depth=6, bootstrap=False),\n",
    "        'XGBoost': xgb.XGBClassifier(random_state=42, n_estimators=300, max_depth=6, learning_rate=0.01),\n",
    "        'AdaBoost': AdaBoostClassifier(random_state=42, n_estimators=300, learning_rate=0.01)\n",
    "    }\n",
    "    for model_name, model in models.items():\n",
    "        classifier_dict[company][model_name] = evaluate_model(X_train, X_test, Y_train, Y_test, model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_dict = {}\n",
    "totals_dict['volume'] = []\n",
    "for model in classifier_dict[company].keys():\n",
    "    totals_dict[model] = {}\n",
    "    totals_dict[model]['accuracy'] = []\n",
    "    totals_dict[model]['precision'] = []\n",
    "    totals_dict[model]['recall'] = []\n",
    "    totals_dict[model]['f1'] = []\n",
    "\n",
    "for company in classifier_dict.keys():\n",
    "    df = clusters_dict[company]['model'].df_input\n",
    "    df[df[\"OPDRACHTGEVERNAAM\"] == company]\n",
    "\n",
    "    totals_dict['volume'].append(df[\"PALLETPLAATSEN\"].sum())\n",
    "    for model in classifier_dict[company].keys():\n",
    "        totals_dict[model]['accuracy'].append(classifier_dict[company][model]['accuracy'])\n",
    "        totals_dict[model]['precision'].append(classifier_dict[company][model]['precision'])\n",
    "        totals_dict[model]['recall'].append(classifier_dict[company][model]['recall'])\n",
    "        totals_dict[model]['f1'].append(classifier_dict[company][model]['f1'])\n",
    "\n",
    "\n",
    "for model in totals_dict:\n",
    "    if model != \"volume\":\n",
    "        print(model)\n",
    "        for score in totals_dict[model]:\n",
    "            print(score, np.mean(totals_dict[model][score]))\n",
    "print(\"==================================\")\n",
    "# print weighed scores\n",
    "total_pallets = sum(totals_dict['volume'])\n",
    "totals_dict[\"weight\"] = totals_dict['volume']/total_pallets\n",
    "for model in totals_dict:\n",
    "    if model != \"volume\" and model != \"weight\":\n",
    "        print(model)\n",
    "        for score in totals_dict[model]:\n",
    "            print(score, sum(totals_dict[model][score]* totals_dict[\"weight\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot for each company and the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "for company in classifier_dict:\n",
    "    classifier_dict[company]['fakename'] = clusters_dict[company]['fakename']\n",
    "\n",
    "biggest_companies_10 = list(classifier_dict.keys())[0:10] \n",
    "\n",
    "# Initialize the plot with a larger figure size\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(biggest_companies_10))\n",
    "\n",
    "# Model names\n",
    "model_names = ['Random Forest', 'XGBoost', 'AdaBoost']\n",
    "\n",
    "# Plot recall scores for each model\n",
    "for i, model_name in enumerate(model_names):\n",
    "    recall_scores = [classifier_dict[company][model_name]['recall'] for company in biggest_companies_10]\n",
    "    bar_positions = index + i * bar_width\n",
    "    ax.bar(bar_positions, recall_scores, bar_width, label=model_name)\n",
    "\n",
    "# Generate labels \"Company A\", \"Company B\", etc., for the top 10 companies\n",
    "company_labels = [classifier_dict[company]['fakename'] for company in biggest_companies_10]\n",
    "\n",
    "# Set plot details\n",
    "ax.set_ylabel('Recall Scores', fontsize=16)\n",
    "ax.set_title('Recall Scores for Top 10 Companies Across Models', fontsize=26)\n",
    "ax.set_xticks(index + bar_width)\n",
    "plt.yticks(fontsize=16)\n",
    "ax.set_xticklabels(company_labels, rotation=45, fontsize=16)  # Rotate labels for better readability\n",
    "ax.legend(fontsize=16, loc='lower left')\n",
    "\n",
    "plt.show()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "for company in classifier_dict:\n",
    "    classifier_dict[company]['fakename'] = clusters_dict[company]['fakename']\n",
    "\n",
    "biggest_companies_10 = list(classifier_dict.keys())[0:10] \n",
    "\n",
    "# Initialize the plot with a larger figure size\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(biggest_companies_10))\n",
    "\n",
    "# Model names\n",
    "model_names = ['Random Forest', 'XGBoost', 'AdaBoost']\n",
    "\n",
    "# Plot recall scores for each model\n",
    "for i, model_name in enumerate(model_names):\n",
    "    recall_scores = [classifier_dict[company][model_name]['f1'] for company in biggest_companies_10]\n",
    "    bar_positions = index + i * bar_width\n",
    "    ax.bar(bar_positions, recall_scores, bar_width, label=model_name)\n",
    "\n",
    "# Generate labels \"Company A\", \"Company B\", etc., for the top 10 companies\n",
    "company_labels = [classifier_dict[company]['fakename'] for company in biggest_companies_10]\n",
    "\n",
    "# Set plot details with specified font sizes\n",
    "ax.set_ylabel('F1 Scores', fontsize=16)\n",
    "ax.set_title('F1 Scores for Top 10 Companies Across Models', fontsize=26)\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(company_labels, rotation=45, fontsize=16)  # Rotate labels for better readability\n",
    "ax.legend(fontsize=16, loc='lower left')\n",
    "plt.yticks(fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "for company in classifier_dict:\n",
    "    classifier_dict[company]['fakename'] = clusters_dict[company]['fakename']\n",
    "\n",
    "biggest_companies_10 = list(classifier_dict.keys())[0:10] \n",
    "\n",
    "# Initialize the plot with a larger figure size\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(biggest_companies_10))\n",
    "\n",
    "# Model names\n",
    "model_names = ['Random Forest', 'XGBoost', 'AdaBoost']\n",
    "\n",
    "# Plot recall scores for each model\n",
    "for i, model_name in enumerate(model_names):\n",
    "    recall_scores = [classifier_dict[company][model_name]['accuracy'] for company in biggest_companies_10]\n",
    "    bar_positions = index + i * bar_width\n",
    "    ax.bar(bar_positions, recall_scores, bar_width, label=model_name)\n",
    "\n",
    "# Generate labels \"Company A\", \"Company B\", etc., for the top 10 companies\n",
    "company_labels = [classifier_dict[company]['fakename'] for company in biggest_companies_10]\n",
    "\n",
    "# Set plot details\n",
    "ax.set_ylabel('Acccuracy Scores')\n",
    "ax.set_title('Acccuracy Scores for Top 10 Companies Across Models')\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(company_labels, rotation=45)  # Rotate labels for better readability\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "for company in classifier_dict:\n",
    "    classifier_dict[company]['fakename'] = clusters_dict[company]['fakename']\n",
    "\n",
    "biggest_companies_10 = list(classifier_dict.keys())[0:10] \n",
    "\n",
    "# Initialize the plot with a larger figure size\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "bar_width = 0.25\n",
    "index = np.arange(len(biggest_companies_10))\n",
    "\n",
    "# Model names\n",
    "model_names = ['Random Forest', 'XGBoost', 'AdaBoost']\n",
    "\n",
    "# Plot recall scores for each model\n",
    "for i, model_name in enumerate(model_names):\n",
    "    recall_scores = [classifier_dict[company][model_name]['precision'] for company in biggest_companies_10]\n",
    "    bar_positions = index + i * bar_width\n",
    "    ax.bar(bar_positions, recall_scores, bar_width, label=model_name)\n",
    "\n",
    "# Generate labels \"Company A\", \"Company B\", etc., for the top 10 companies\n",
    "company_labels = [classifier_dict[company]['fakename'] for company in biggest_companies_10]\n",
    "\n",
    "# Set plot details\n",
    "ax.set_ylabel('Precission Scores')\n",
    "ax.set_title('Precission Scores for Top 10 Companies Across Models')\n",
    "ax.set_xticks(index + bar_width)\n",
    "ax.set_xticklabels(company_labels, rotation=45)  # Rotate labels for better readability\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier CV XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*applymap has been deprecated.*\")\n",
    "\n",
    "# Assuming df_condensed is already defined and loaded with data\n",
    "categorical_features = ['LAADPC', 'dayofweekcreation', 'weeknr']\n",
    "continuous_features = ['PALLETPLAATSEN', 'AANTALORDERS']\n",
    "features = categorical_features + continuous_features\n",
    "\n",
    "classifier_dict3 = {}\n",
    "\n",
    "for company in clusters_dict: \n",
    "    print(\"==================================\")\n",
    "    print(f\"Training for {company}\")\n",
    "\n",
    "    df_condensed = clusters_dict[company][\"model\"].condense_orders()\n",
    "    classifier_dict3[company] = {}\n",
    "    # Filter data for the specific company\n",
    "    df_to_use = df_condensed[df_condensed[\"OPDRACHTGEVERNAAM\"] == company]\n",
    "    region_columns = [col for col in df_condensed.columns if col.startswith('REGION_')]\n",
    "\n",
    "    # Calculate the totals for each region column and aquire targets\n",
    "    totals = df_to_use[region_columns].sum()\n",
    "    non_zero_totals = totals[totals != 0]\n",
    "    targets = list(non_zero_totals.keys())\n",
    "\n",
    "    df_to_use = df_to_use[features + targets]\n",
    "\n",
    "    # Prepare the feature matrix and target matrix\n",
    "    X = df_to_use[features]\n",
    "    Y = df_to_use[targets]\n",
    "\n",
    "    # Convert target values to binary (0 = False, 1 = True)\n",
    "    Y_binary = Y.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    # Handling categorical variables\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_categorical_features = encoder.fit_transform(df_to_use[categorical_features])\n",
    "\n",
    "    # Scale continuous variables\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_continuous_features = scaler.fit_transform(df_to_use[continuous_features])\n",
    "\n",
    "    # Combine all features\n",
    "    X_formatted = np.hstack([scaled_continuous_features, encoded_categorical_features])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_formatted, Y_binary, test_size=0.2, random_state=42)\n",
    "\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'max_depth': [20, 30, 40, 50],\n",
    "        'learning_rate': [0.001, 0.005, 0.01, 0.05, 0.1]\n",
    "    }\n",
    "\n",
    "    # Optimize for recall\n",
    "    def custom_recall(y_true, y_pred):\n",
    "        return recall_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    custom_scorer = make_scorer(custom_recall)\n",
    "\n",
    "    model = GridSearchCV(xgb.XGBClassifier(random_state=42), param_grid_xgb, cv=3, scoring=custom_scorer, verbose=0)\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "    best_model = model.best_estimator_\n",
    "    best_params = model.best_params_\n",
    "    classifier_dict3[company]['recall'] = evaluate_model(X_train, X_test, Y_train, Y_test, best_model, \"XGBoostRecall\")\n",
    "    classifier_dict3[company]['recall']['best_params'] = best_params\n",
    "    print(f\"Best parameters are: {best_params}\")\n",
    "    print(f\"Accuracy: {classifier_dict3[company]['recall']['accuracy']}, Recall: {classifier_dict3[company]['recall']['recall']}, Precision: {classifier_dict3[company]['recall']['precision']}, F1: {classifier_dict3[company]['recall']['f1']}\")\n",
    "    clusters_dict[company][\"recall_params\"] = best_params\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    \n",
    "    # Optimize for f1\n",
    "    def custom_f1(y_true, y_pred):\n",
    "        return f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "    custom_scorer = make_scorer(custom_f1)\n",
    "\n",
    "    model = GridSearchCV(xgb.XGBClassifier(random_state=42), param_grid_xgb, cv=3, scoring=custom_scorer, verbose=0)\n",
    "    model.fit(X_train, Y_train)\n",
    "    best_model = model.best_estimator_\n",
    "    best_params = model.best_params_\n",
    "    classifier_dict3[company]['f1'] = evaluate_model(X_train, X_test, Y_train, Y_test, best_model, \"XGBoostRecall\")\n",
    "    classifier_dict3[company]['f1']['best_params'] = best_params\n",
    "    print(f\"Best parameters are: {best_params}\")\n",
    "    print(f\"Accuracy: {classifier_dict3[company][model_name]['accuracy']}, Recall: {classifier_dict3[company]['f1']['recall']}, Precision: {classifier_dict3[company]['f1']['precision']}, F1: {classifier_dict3[company]['f1']['f1']}\")\n",
    "    clusters_dict[company][\"f1_params\"] = best_params\n",
    "    print(\"==================================\")\n",
    "\n",
    "\n",
    "\n",
    " # remove GSE object from dictionary:\n",
    "final_dict_export = {}\n",
    "for company in clusters_dict:\n",
    "    final_dict_export[company] = clusters_dict[company].copy()\n",
    "    final_dict_export[company].pop('model', None)\n",
    "    final_dict_export[company].pop('CPC_dict', None)\n",
    "    final_dict_export[company].pop('CPC_dict2', None)\n",
    "\n",
    "\n",
    "# save final_dict to a json file\n",
    "import json\n",
    "with open('dict_final_class_parameters.json', 'w') as file:\n",
    "    json.dump(final_dict_export, file, indent=4)  # indent=4 is optional for pretty printing      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Classifier results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('dict_incl_class_parameters.json', 'r') as file:\n",
    "    classifier_dict = json.load(file)\n",
    "\n",
    "for company in classifier_dict:\n",
    "    classifier_dict[company].pop('CPC_dict2')\n",
    "    classifier_dict[company].pop('CPC_dict')\n",
    "    classifier_dict[company]['model'] = clusters_dict[company]['model']\n",
    "\n",
    "categorical_features = ['LAADPC', 'dayofweekcreation', 'weeknr']\n",
    "continuous_features = ['PALLETPLAATSEN', 'AANTALORDERS']\n",
    "features = categorical_features + continuous_features\n",
    "for company in classifier_dict:\n",
    "    print(f\"Processing {company}\")\n",
    "    df_condensed = clusters_dict[company][\"model\"].condense_orders()   \n",
    "    df_condensed[\"weeknr\"] = df_condensed[\"CREATIONDATETIME\"].dt.strftime(\"%V\")\n",
    "    region_columns = [col for col in df_condensed.columns if col.startswith('REGION_')]\n",
    "        \n",
    "    # Filter data for the specific company\n",
    "    df_to_use = df_condensed[df_condensed[\"OPDRACHTGEVERNAAM\"] == company]\n",
    "\n",
    "    # Calculate the totals for each region column and aquire targets\n",
    "    totals = df_to_use[region_columns].sum()\n",
    "    non_zero_totals = totals[totals != 0]\n",
    "    targets = list(non_zero_totals.keys())\n",
    "\n",
    "    df_to_use = df_to_use[features + targets]\n",
    "\n",
    "    # Prepare the feature matrix and target matrix\n",
    "    X = df_to_use[features]\n",
    "    Y = df_to_use[targets]\n",
    "\n",
    "    # Convert target values to binary (0 = False, 1 = True)\n",
    "    Y_binary = Y.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    # Handling categorical variables\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    encoded_categorical_features = encoder.fit_transform(df_to_use[categorical_features])\n",
    "\n",
    "    # Scale continuous variables\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_continuous_features = scaler.fit_transform(df_to_use[continuous_features])\n",
    "\n",
    "    # Combine all features\n",
    "    X_formatted = np.hstack([scaled_continuous_features, encoded_categorical_features])\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_formatted, Y_binary, test_size=0.2, random_state=41)\n",
    "\n",
    "    model_recall = xgb.XGBClassifier(random_state=42, \n",
    "                                     n_estimators=classifier_dict[company]['recall_params']['n_estimators'],\n",
    "                                     max_depth=classifier_dict[company]['recall_params']['max_depth'], \n",
    "                                     learning_rate=classifier_dict[company]['recall_params']['learning_rate'])\n",
    "    model_f1 = xgb.XGBClassifier(random_state=42,\n",
    "                                    n_estimators=classifier_dict[company]['f1_params']['n_estimators'],\n",
    "                                    max_depth=classifier_dict[company]['f1_params']['max_depth'], \n",
    "                                    learning_rate=classifier_dict[company]['f1_params']['learning_rate'])\n",
    "\n",
    "    classifier_dict[company]['recall_model_scores'] = evaluate_model(X_train, X_test, Y_train, Y_test, model_recall, 'XGBoost_recall')\n",
    "    classifier_dict[company]['f1_model_scores'] = evaluate_model(X_train, X_test, Y_train, Y_test, model_f1, 'XGBoost_f1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pallets = sum([classifier_dict[company]['model'].df_input['PALLETPLAATSEN'].sum() for company in classifier_dict])\n",
    "for company in classifier_dict:\n",
    "    classifier_dict[company]['pallets'] = classifier_dict[company]['model'].df_input['PALLETPLAATSEN'].sum()\n",
    "    classifier_dict[company]['weight'] = classifier_dict[company]['pallets'] / total_pallets\n",
    "\n",
    "print(\"Mean accuracy optimized on recall \", np.mean([x for x in [classifier_dict[company]['recall_model_scores']['accuracy'] for company in classifier_dict]]))\n",
    "print(\"Mean precision optimized on recall \", np.mean([x for x in [classifier_dict[company]['recall_model_scores']['precision'] for company in classifier_dict]]))\n",
    "print(\"Mean recall optimized on recall \", np.mean([x for x in [classifier_dict[company]['recall_model_scores']['recall'] for company in classifier_dict]]))\n",
    "print(\"Mean f1 optimized on recall \", np.mean([x for x in [classifier_dict[company]['recall_model_scores']['f1'] for company in classifier_dict]]))\n",
    "\n",
    "print(\"Mean accuracy optimized on f1     \", np.mean([x for x in [classifier_dict[company]['f1_model_scores']['accuracy'] for company in classifier_dict]]))\n",
    "print(\"Mean precision optimized on f1     \", np.mean([x for x in [classifier_dict[company]['f1_model_scores']['precision'] for company in classifier_dict]]))\n",
    "print(\"Mean recall optimized on f1     \", np.mean([x for x in [classifier_dict[company]['f1_model_scores']['recall'] for company in classifier_dict]]))\n",
    "print(\"Mean f1 optimized on f1     \", np.mean([x for x in [classifier_dict[company]['f1_model_scores']['f1'] for company in classifier_dict]]))\n",
    "print(\" ==================================\")\n",
    "\n",
    "print(\"weighed scores\")\n",
    "print(\"Mean accuracy optimized on recall \", sum([classifier_dict[company]['recall_model_scores']['accuracy']*classifier_dict[company]['weight'] for company in classifier_dict]))\n",
    "print(\"Mean precision optimized on recall \", sum([classifier_dict[company]['recall_model_scores']['precision']*classifier_dict[company]['weight'] for company in classifier_dict]))\n",
    "print(\"Mean recall optimized on recall \", sum([classifier_dict[company]['recall_model_scores']['recall']*classifier_dict[company]['weight'] for company in classifier_dict]))\n",
    "print(\"Mean f1 optimized on recall \", sum([classifier_dict[company]['recall_model_scores']['f1']*classifier_dict[company]['weight'] for company in classifier_dict]))\n",
    "\n",
    "print(\"Mean accuracy optimized on f1     \", sum([classifier_dict[company]['f1_model_scores']['accuracy']*classifier_dict[company]['weight'] for company in classifier_dict]))\n",
    "print(\"Mean precision optimized on f1     \", sum([classifier_dict[company]['f1_model_scores']['precision']*classifier_dict[company]['weight'] for company in classifier_dict]))\n",
    "print(\"Mean recall optimized on f1     \", sum([classifier_dict[company]['f1_model_scores']['recall']*classifier_dict[company]['weight'] for company in classifier_dict]))\n",
    "print(\"Mean f1 optimized on f1     \", sum([classifier_dict[company]['f1_model_scores']['f1']*classifier_dict[company]['weight'] for company in classifier_dict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_companies = sorted(classifier_dict, key=lambda x: classifier_dict[x]['pallets'], reverse=True)[:20]\n",
    "\n",
    "def plot_grouped_bars(dataframe, chunk_size, title=None, max_plots=None):\n",
    "    chunks = len(dataframe) // chunk_size + (1 if len(dataframe) % chunk_size > 0 else 0)\n",
    "    \n",
    "    for i in range(chunks):\n",
    "        if max_plots is not None and i >= max_plots:\n",
    "            break\n",
    "        chunk = dataframe.iloc[i * chunk_size:(i + 1) * chunk_size]\n",
    "        if title is None:\n",
    "            title = f'Model Performance Metrics for Companies {i * chunk_size + 1} to {(i + 1) * chunk_size}'\n",
    "        ax = chunk.plot(kind='bar', figsize=(12, 8), title=title)\n",
    "        ax.set_xlabel('Company')\n",
    "        ax.set_ylabel('Scores')\n",
    "        ax.grid(True)\n",
    "        plt.legend(title='Metric', loc='lower left')\n",
    "        plt.xticks(rotation=45, ticks=range(len(chunk)), labels=chunk['Company'])\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Company': [classifier_dict[company]['fakename'] for company in biggest_companies],\n",
    "    'Recall optimized model - Accuracy': [classifier_dict[company]['recall_model_scores']['accuracy'] for company in biggest_companies],\n",
    "    'Recall optimized model - Precision': [classifier_dict[company]['recall_model_scores']['precision'] for company in biggest_companies],\n",
    "    'Recall optimized model - Recall': [classifier_dict[company]['recall_model_scores']['recall'] for company in biggest_companies],\n",
    "    'Recall optimized model - F1': [classifier_dict[company]['recall_model_scores']['f1'] for company in biggest_companies],\n",
    "    'F1 optimized model - Accuracy': [classifier_dict[company]['f1_model_scores']['accuracy'] for company in biggest_companies],\n",
    "    'F1 optimized model - Precision': [classifier_dict[company]['f1_model_scores']['precision'] for company in biggest_companies],\n",
    "    'F1 optimized model - Recall': [classifier_dict[company]['f1_model_scores']['recall'] for company in biggest_companies],\n",
    "    'F1 optimized model - F1': [classifier_dict[company]['f1_model_scores']['f1'] for company in biggest_companies]\n",
    "})\n",
    "\n",
    "plot_grouped_bars(data, 10, 'Model Performance Metrics for Top 10 Companies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final parameters for regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the final_dict from file\n",
    "import json\n",
    "with open('clusters_final_dict.json', 'r') as file:\n",
    "    clusters_dict = json.load(file)\n",
    "\n",
    "# read the final_dict from file\n",
    "import json\n",
    "with open('dict_incl_class_parameters.json', 'r') as file:\n",
    "    classifier_dict = json.load(file)\n",
    "companies = list(clusters_dict.keys())\n",
    "for company in clusters_dict:\n",
    "    df_to_use = df_orders[(df_orders['OPDRACHTGEVERNAAM'] == company)]\n",
    "    clusters_dict[company][\"GSE\"] = GeoSpatialEncoder(PC_obj)\n",
    "    clusters_dict[company][\"GSE\"].set_verbose(False)\n",
    "    clusters_dict[company][\"GSE\"].set_input_df(df_to_use)\n",
    "    clusters_dict[company][\"GSE\"].clean_input_df()\n",
    "    clusters_dict[company][\"GSE\"].train_kmeans(clusters_dict[company]['nclusters'], 'SHIPMENT_COUNT')\n",
    "    clusters_dict[company][\"Classifier\"] = xgb.XGBClassifier(random_state=42,\n",
    "                                                              n_estimators=classifier_dict[company]['recall_params']['n_estimators'],\n",
    "                                                              max_depth=classifier_dict[company]['recall_params']['max_depth'],\n",
    "                                                              learning_rate=classifier_dict[company]['recall_params']['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in companies:\n",
    "    clusters_dict[company+\"_f1\"] = clusters_dict[company].copy()\n",
    "    clusters_dict[company+\"_f1\"][\"Classifier\"] = xgb.XGBClassifier(random_state=42,\n",
    "                                                                   n_estimators=classifier_dict[company]['f1_params']['n_estimators'],\n",
    "                                                                    max_depth=classifier_dict[company]['f1_params']['max_depth'],\n",
    "                                                                    learning_rate=classifier_dict[company]['f1_params']['learning_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of pipeline class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pipeline:\n",
    "    def __init__(self, classifier, regressor, mode, df, company):\n",
    "        self.classifier = classifier\n",
    "        self.regressor = regressor\n",
    "        self.mode = mode\n",
    "        self.df = df\n",
    "        self.company = company\n",
    "        self.encoder = OneHotEncoder(sparse_output=False)\n",
    "        self.scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "        self.categorical_features = ['LAADPC', 'dayofweekcreation', 'weeknr']\n",
    "        self.continuous_features = ['PALLETPLAATSEN', 'AANTALORDERS']\n",
    "\n",
    "    def prepare_X_values(self, X):\n",
    "        encoded_categorical_features = self.encoder.transform(X[categorical_features])\n",
    "        scaled_continuous_features = self.scaler.transform(X[continuous_features])\n",
    "        return np.hstack([scaled_continuous_features, encoded_categorical_features])\n",
    "    \n",
    "    def get_X_and_Y(self):\n",
    "        \n",
    "        features = self.categorical_features + self.continuous_features\n",
    "\n",
    "        region_columns = [col for col in self.df.columns if col.startswith('REGION_')]\n",
    "        # Filter data for the specific company\n",
    "        df_to_use = self.df\n",
    "\n",
    "        # Calculate the totals for each region column and aquire targets\n",
    "        totals = df_to_use[region_columns].sum()\n",
    "        non_zero_totals = totals[totals != 0]\n",
    "        targets = list(non_zero_totals.keys())\n",
    "              \n",
    "        encoded_categorical_features = self.encoder.fit_transform(df_to_use[self.categorical_features])\n",
    "        scaled_continuous_features = self.scaler.fit_transform(df_to_use[self.continuous_features])\n",
    "\n",
    "        # Combine all features\n",
    "        X_formatted = np.hstack([scaled_continuous_features, encoded_categorical_features])\n",
    "        Y = df_to_use[targets]  \n",
    "        \n",
    "        self.X_train, self.X_test, self.Y_train, self.Y_test = train_test_split(X_formatted, Y, test_size=0.2, random_state=42)\n",
    "        self.Y_train_binary = self.Y_train.applymap(lambda x: 1 if x > 0 else 0)\n",
    "        self.Y_test_binary = self.Y_test.applymap(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "    def add_binary_to_X(self, X, Y_binary):\n",
    "        return np.hstack([X, Y_binary])\n",
    "\n",
    "    def get_original_palletplaatsen(self, X_scaled):\n",
    "        original_values = self.scaler.inverse_transform(np.column_stack((X_scaled[:, 0], X_scaled[:, 1])))\n",
    "        original_df = pd.DataFrame(original_values, columns=['PALLETPLAATSEN', 'AANTALORDERS'])\n",
    "        return original_df[\"PALLETPLAATSEN\"]\n",
    "\n",
    "    def train_classifier(self):\n",
    "        self.classifier.fit(self.X_train, self.Y_train_binary)\n",
    "\n",
    "    def predict_classifier(self, X):\n",
    "        Y_pred_df = pd.DataFrame(self.classifier.predict(X), columns=self.Y_train_binary.columns)\n",
    "        return Y_pred_df\n",
    "    \n",
    "    def score_classifier(self):\n",
    "        Y_pred = self.predict_classifier(self.X_test)\n",
    "        zerodiv = 1\n",
    "        accuracy = accuracy_score( self.Y_test_binary.values.flatten(), Y_pred.values.flatten())\n",
    "        precision = precision_score( self.Y_test_binary,  Y_pred, average='macro', zero_division=zerodiv)\n",
    "        recall = recall_score( self.Y_test_binary,  Y_pred, average='macro', zero_division=zerodiv)\n",
    "        f1 = f1_score(self.Y_test_binary, Y_pred, average='macro', zero_division=zerodiv)\n",
    "        \n",
    "        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "    \n",
    "    def predict_destination(self, X):\n",
    "        inputvalues = self.prepare_X_values(X)\n",
    "        return self.classifier.predict(inputvalues) \n",
    "\n",
    "    def predict_demands(self, X):\n",
    "        inputvalues = self.prepare_X_values(X)\n",
    "        pred_test_Y = self.predict_classifier(inputvalues)\n",
    "        X = self.add_binary_to_X(inputvalues, pred_test_Y)\n",
    "        Y_pred = self.regressor.predict(X)\n",
    "        Y_pred = self.filter_by_binary(Y_pred, pred_test_Y)\n",
    "        return Y_pred\n",
    "\n",
    "    def train_clean_regressor(self):\n",
    "        X = self.add_binary_to_X(self.X_train, self.Y_train_binary)\n",
    "        self.regressor.fit(X, self.Y_train)\n",
    "        \n",
    "    def train_dirty_regressor(self):\n",
    "        pred_train_Y = self.predict_classifier(self.X_train)\n",
    "        X = self.add_binary_to_X(self.X_train, pred_train_Y)\n",
    "        self.regressor.fit(X, self.Y_train)\n",
    "\n",
    "    def train_paralel_regressor(self):\n",
    "        self.regressor.fit(self.X_train, self.Y_train)\n",
    "\n",
    "\n",
    "    def score_clean_regressor(self):\n",
    "        X = self.add_binary_to_X(self.X_test, self.Y_test_binary)\n",
    "        Y_pred = self.regressor.predict(X)\n",
    "        mse = mean_squared_error(self.Y_test, Y_pred)\n",
    "        r2 = r2_score(self.Y_test, Y_pred)\n",
    "        return {\"mean_squared_error\": mse, \"r2_score\": r2}\n",
    "    \n",
    "    def score_dirty_regressor(self):\n",
    "        pred_test_Y = self.predict_classifier(self.X_test)\n",
    "        X = self.add_binary_to_X(self.X_test, pred_test_Y)\n",
    "        Y_pred = self.regressor.predict(X)\n",
    "        mse = mean_squared_error(self.Y_test, Y_pred)\n",
    "        r2 = r2_score(self.Y_test, Y_pred)\n",
    "        return {\"mean_squared_error\": mse, \"r2_score\": r2}\n",
    "    \n",
    "    def score_paralel_regressor(self):\n",
    "        Y_pred = self.regressor.predict(self.X_test)\n",
    "        mse = mean_squared_error(self.Y_test, Y_pred)\n",
    "        r2 = r2_score(self.Y_test, Y_pred)\n",
    "        return {\"mean_squared_error\": mse, \"r2_score\": r2}\n",
    "    \n",
    "\n",
    "    def filter_by_binary(self, df_float, df_binary):\n",
    "        df_float = pd.DataFrame(df_float, columns=self.Y_train.columns)\n",
    "        # Ensure the dataframes have the same shape\n",
    "        if df_float.shape != df_binary.shape:\n",
    "            raise ValueError(\"The two dataframes must have the same shape.\")\n",
    "        \n",
    "        # Apply the mask\n",
    "        result_df = df_float.where(df_binary == 1, 0)\n",
    "        return result_df\n",
    "    \n",
    "    def softmax_to_demand(self, df_predicted, given_demand):\n",
    "        # Ensure given_demand is a Series for iteration\n",
    "        df_predicted.reset_index(inplace=True, drop=True)\n",
    "        given_demand.reset_index(inplace=True, drop=True)\n",
    "        given_demand = given_demand.squeeze()  # This works if given_demand is a DataFrame with one column or a Series\n",
    "        \n",
    "        # Iterate over each row by index, assuming both df_predicted and given_demand use the same index\n",
    "        for row_index in df_predicted.index:\n",
    "            demand = given_demand.loc[row_index]\n",
    "            row_values = df_predicted.loc[row_index]\n",
    "            \n",
    "            if row_values.sum() == 0:\n",
    "                continue  # Skip rows where the sum is zero to avoid division by zero\n",
    "\n",
    "            # Apply scaling factor only to non-zero elements\n",
    "            non_zero_indices = row_values != 0\n",
    "            non_zero_values = row_values[non_zero_indices]\n",
    "            scaling_factor = demand / non_zero_values.sum()\n",
    "            \n",
    "            # Scale and apply softmax logic to non-zero values\n",
    "            non_zero_adjusted = np.exp(non_zero_values * scaling_factor - np.max(non_zero_values * scaling_factor))\n",
    "            df_predicted.loc[row_index, non_zero_indices] = np.round((non_zero_adjusted / non_zero_adjusted.sum()) * demand)\n",
    "\n",
    "        return df_predicted\n",
    "\n",
    "    def scale_to_demand(self, df_predicted, given_demand):\n",
    "        df_predicted.reset_index(inplace=True, drop=True)\n",
    "        given_demand.reset_index(inplace=True, drop=True)\n",
    "        for row, demand in given_demand.items():  # assuming given_demand is a dict or series\n",
    "            total_predicted = df_predicted.loc[row].sum()\n",
    "            if total_predicted == 0:\n",
    "                continue  # Skip if no demand is predicted to avoid division by zero\n",
    "            scaling_factor = demand / total_predicted\n",
    "            df_predicted.loc[row] = np.round(df_predicted.loc[row] * scaling_factor)\n",
    "        return df_predicted\n",
    "    \n",
    "    def score_pipeline(self):\n",
    "        pred_test_Y = self.predict_classifier(self.X_test)\n",
    "        X = self.add_binary_to_X(self.X_test, pred_test_Y)\n",
    "        Y_pred = self.regressor.predict(X)\n",
    "        Y_pred = self.filter_by_binary(Y_pred, pred_test_Y)\n",
    "        mse = mean_squared_error(self.Y_test, Y_pred)\n",
    "        r2 = r2_score(self.Y_test, Y_pred)\n",
    "        return {\"mean_squared_error\": mse, \"r2_score\": r2}\n",
    "    \n",
    "    def score_pipeline_with_correction(self):\n",
    "        pred_test_Y = self.predict_classifier(self.X_test)\n",
    "        X = self.add_binary_to_X(self.X_test, pred_test_Y)\n",
    "        Y_pred = self.regressor.predict(X)\n",
    "        Y_pred = self.filter_by_binary(Y_pred, pred_test_Y)\n",
    "        original_palletplaatsen = self.get_original_palletplaatsen(self.X_test)\n",
    "        Y_pred = self.scale_to_demand(Y_pred, original_palletplaatsen)\n",
    "        mse = mean_squared_error(self.Y_test, Y_pred)\n",
    "        r2 = r2_score(self.Y_test, Y_pred)\n",
    "        return {\"mean_squared_error\": mse, \"r2_score\": r2}\n",
    "    \n",
    "    def score_pipeline_with_correction2(self):\n",
    "        pred_test_Y = self.predict_classifier(self.X_test)\n",
    "        X = self.add_binary_to_X(self.X_test, pred_test_Y)\n",
    "        Y_pred = self.regressor.predict(X)\n",
    "        Y_pred = self.filter_by_binary(Y_pred, pred_test_Y)\n",
    "        original_palletplaatsen = self.get_original_palletplaatsen(self.X_test)\n",
    "        Y_pred = self.softmax_to_demand(Y_pred, original_palletplaatsen)\n",
    "        mse = mean_squared_error(self.Y_test, Y_pred)\n",
    "        r2 = r2_score(self.Y_test, Y_pred)\n",
    "        return {\"mean_squared_error\": mse, \"r2_score\": r2}\n",
    "\n",
    "\n",
    "    \n",
    "    def score_paralel_pipeline(self):\n",
    "        Y_pred_bin = self.predict_classifier(self.X_test)\n",
    "        Y_pred = self.regressor.predict(self.X_test)\n",
    "        Y_pred_filtered = self.filter_by_binary(Y_pred, Y_pred_bin)\n",
    "        mse = mean_squared_error(self.Y_test, Y_pred_filtered)\n",
    "        r2 = r2_score(self.Y_test, Y_pred_filtered)\n",
    "        return {\"mean_squared_error\": mse, \"r2_score\": r2}\n",
    "    \n",
    "    def score_paralel_pipeline_with_correction(self):\n",
    "        Y_pred_bin = self.predict_classifier(self.X_test)\n",
    "        Y_pred = self.regressor.predict(self.X_test)\n",
    "        Y_pred_filtered = self.filter_by_binary(Y_pred, Y_pred_bin)\n",
    "        original_palletplaatsen = self.get_original_palletplaatsen(self.X_test)\n",
    "        Y_pred_scaled = self.scale_to_demand(Y_pred_filtered, original_palletplaatsen)\n",
    "        mse = mean_squared_error(self.Y_test, Y_pred_scaled)\n",
    "        r2 = r2_score(self.Y_test, Y_pred_scaled)\n",
    "        return {\"mean_squared_error\": mse, \"r2_score\": r2}\n",
    "    \n",
    "    def score_paralel_pipeline_with_correction2(self):\n",
    "        Y_pred_bin = self.predict_classifier(self.X_test)\n",
    "        Y_pred = self.regressor.predict(self.X_test)\n",
    "        Y_pred_filtered = self.filter_by_binary(Y_pred, Y_pred_bin)\n",
    "        original_palletplaatsen = self.get_original_palletplaatsen(self.X_test)\n",
    "        Y_pred_softmax = self.softmax_to_demand(Y_pred_filtered, original_palletplaatsen)\n",
    "        mse = mean_squared_error(self.Y_test, Y_pred_softmax)\n",
    "        r2 = r2_score(self.Y_test, Y_pred_softmax)\n",
    "        return {\"mean_squared_error\": mse, \"r2_score\": r2}\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running pipeline class and finding best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom.Pipeline import Pipeline\n",
    "results_dict = {}\n",
    "for company in clusters_dict:\n",
    "    results_dict[company] = {}\n",
    "    print(company)\n",
    "    print(\"====================================\")\n",
    "    pipe1 = Pipeline(clusters_dict[company][\"Classifier\"], None, \"test\", clusters_dict[company][\"GSE\"].condense_orders(), company)\n",
    "    pipe1.get_X_and_Y()\n",
    "    print(\"Classifier\")\n",
    "    pipe1.train_classifier()\n",
    "    # prepare_X = pipe1.prepare_X_values(pipe1.X_test)\n",
    "    results_dict[company][\"classifier\"] = pipe1.score_classifier()\n",
    "    print(results_dict[company][\"classifier\"])\n",
    "\n",
    "    best_r2_clean = -9999\n",
    "    best_r2_dirty = -9999\n",
    "    best_r2_parallel = -9999 \n",
    "\n",
    "    for n_est in [1, 20 ,50, 100, 200, 300]:\n",
    "        for max_depth in [1,3,5, 10, 20, 50]:\n",
    "            for learn_rate in [0.01, 0.05, 0.1]:\n",
    "                paramset = (n_est, max_depth, learn_rate)\n",
    "                results_dict[company][paramset] = {}                \n",
    "                # print(paramset)\n",
    "                \n",
    "                xgb_regressor = xgb.XGBRegressor(\n",
    "                    random_state=42,\n",
    "                    n_estimators=n_est, #int(clusters_dict[company]['params']['n_estimators']),\n",
    "                    max_depth=max_depth, #clusters_dict[company]['params']['max_depth'],\n",
    "                    learning_rate= learn_rate #clusters_dict[company]['params']['learning_rate']\n",
    "                )\n",
    "                pipe1.regressor = xgb_regressor\n",
    "\n",
    "                # print(\"Clean regressor\")\n",
    "                pipe1.train_clean_regressor()\n",
    "                results_dict[company][paramset][\"clean_regressor\"] = {}\n",
    "                results_dict[company][paramset][\"clean_regressor\"]['clean_input'] = pipe1.score_clean_regressor()\n",
    "                results_dict[company][paramset][\"clean_regressor\"]['dirty_input'] = pipe1.score_dirty_regressor()\n",
    "                # print(results_dict[company][paramset][\"clean_regressor\"])\n",
    "                results_dict[company][paramset][\"clean_regressor\"][\"pipeline\"] = pipe1.score_pipeline()\n",
    "                # print(results_dict[company][paramset][\"clean_regressor\"][\"pipeline\"])\n",
    "                results_dict[company][paramset][\"clean_regressor\"][\"pipeline_with_correction\"] = pipe1.score_pipeline_with_correction()\n",
    "                # print(results_dict[company][paramset][\"clean_regressor\"][\"pipeline_with_correction\"])\n",
    "                results_dict[company][paramset][\"clean_regressor\"][\"pipeline_with_correction2\"] = pipe1.score_pipeline_with_correction2()\n",
    "                # print(results_dict[company][paramset][\"clean_regressor\"][\"pipeline_with_correction2\"])\n",
    "                \n",
    "\n",
    "                # print(\"Dirty regressor\")\n",
    "                pipe1.train_dirty_regressor()\n",
    "                results_dict[company][paramset][\"dirty_regressor\"] = {}\n",
    "                results_dict[company][paramset][\"dirty_regressor\"]['clean_input'] = pipe1.score_clean_regressor()\n",
    "                results_dict[company][paramset][\"dirty_regressor\"]['dirty_input'] = pipe1.score_dirty_regressor()\n",
    "                # print(results_dict[company][paramset][\"dirty_regressor\"])\n",
    "                results_dict[company][paramset][\"dirty_regressor\"][\"pipeline\"] = pipe1.score_pipeline()\n",
    "                # print(results_dict[company][paramset][\"dirty_regressor\"][\"pipeline\"])\n",
    "                results_dict[company][paramset][\"dirty_regressor\"][\"pipeline_with_correction\"] = pipe1.score_pipeline_with_correction()\n",
    "                # print(results_dict[company][paramset][\"dirty_regressor\"][\"pipeline_with_correction\"])\n",
    "                results_dict[company][paramset][\"dirty_regressor\"][\"pipeline_with_correction2\"] = pipe1.score_pipeline_with_correction2()\n",
    "                # print(results_dict[company][paramset][\"dirty_regressor\"][\"pipeline_with_correction2\"])\n",
    "\n",
    "\n",
    "                # print(\"parallel regressor\")\n",
    "                pipe1.train_parallel_regressor()\n",
    "                results_dict[company][paramset][\"parallel_regressor\"] = pipe1.score_parallel_regressor()\n",
    "                # print(results_dict[company][paramset][\"parallel_regressor\"])\n",
    "                results_dict[company][paramset][\"parallel_regressor\"][\"pipeline\"] = pipe1.score_parallel_pipeline()\n",
    "                # print(results_dict[company][paramset][\"parallel_regressor\"][\"pipeline\"])\n",
    "                results_dict[company][paramset][\"parallel_regressor\"][\"pipeline_with_correction\"] = pipe1.score_parallel_pipeline_with_correction()\n",
    "                # print(results_dict[company][paramset][\"parallel_regressor\"][\"pipeline_with_correction\"])\n",
    "                results_dict[company][paramset][\"parallel_regressor\"][\"pipeline_with_correction2\"] = pipe1.score_parallel_pipeline_with_correction2()\n",
    "                # print(results_dict[company][paramset][\"parallel_regressor\"][\"pipeline_with_correction2\"])\n",
    "                \n",
    "\n",
    "                if results_dict[company][paramset][\"clean_regressor\"]['pipeline'][\"r2_score\"] > best_r2_clean:\n",
    "                    best_r2_clean = results_dict[company][paramset][\"clean_regressor\"]['pipeline'][\"r2_score\"]\n",
    "                    best_params_clean = paramset\n",
    "                    print(f\"Best clean regressor: {best_r2_clean} with parameters: {best_params_clean}\")\n",
    "                if results_dict[company][paramset][\"dirty_regressor\"]['pipeline'][\"r2_score\"] > best_r2_dirty:\n",
    "                    best_r2_dirty = results_dict[company][paramset][\"dirty_regressor\"]['pipeline'][\"r2_score\"]\n",
    "                    best_params_dirty = paramset\n",
    "                    print(f\"Best dirty regressor: {best_r2_dirty} with parameters: {best_params_dirty}\")\n",
    "                if results_dict[company][paramset][\"parallel_regressor\"]['pipeline'][\"r2_score\"] > best_r2_parallel:\n",
    "                    best_r2_parallel = results_dict[company][paramset][\"parallel_regressor\"]['pipeline'][\"r2_score\"]\n",
    "                    best_params_parallel = paramset\n",
    "                    print(f\"Best parallel regressor: {best_r2_parallel} with parameters: {best_params_parallel}\")\n",
    "    print(\"====================================\")\n",
    "    print(f\"Best clean regressor: {best_r2_clean} with parameters: {best_params_clean}\")\n",
    "    print(f\"Best dirty regressor: {best_r2_dirty} with parameters: {best_params_dirty}\")\n",
    "    print(f\"Best parallel regressor: {best_r2_parallel} with parameters: {best_params_parallel}\")\n",
    "    print(\"====================================\")\n",
    "\n",
    "# # save final_dict to a json file\n",
    "final_dict_export = {}\n",
    "for company in results_dict:\n",
    "    final_dict_export[company] = {}\n",
    "    for key in results_dict[company]:\n",
    "        if type(key) == tuple:\n",
    "            final_dict_export[company][str(key[0])+\"_\"+str(key[1])+\"_\"+str(key[2])] = results_dict[company][key].copy()\n",
    "    final_dict_export[company].pop('model', None)\n",
    "    final_dict_export[company].pop('Classifier', None)\n",
    "\n",
    "import json\n",
    "with open('results_dict_pipelinecomparison_recall_f1_v3.json', 'w') as file:\n",
    "    json.dump(final_dict_export, file, indent=4)  # indent=4 is optional for pretty printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export classifier scores to xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Fake Company': [],\n",
    "    'Company': [],\n",
    "    'accuracy': [],\n",
    "    'recall': [],\n",
    "    'precission': [],\n",
    "    'f1': [],\n",
    "}\n",
    "\n",
    "for company in results_dict:\n",
    "    data['Fake Company'].append(clusters_dict[company]['fakename'])\n",
    "    data['Company'].append(company)\n",
    "    data['accuracy'].append(results_dict[company]['classifier']['accuracy'])\n",
    "    data['recall'].append(results_dict[company]['classifier']['recall'])\n",
    "    data['precission'].append(results_dict[company]['classifier']['precision'])\n",
    "    data['f1'].append(results_dict[company]['classifier']['f1'])\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# #export to XLSX\n",
    "# df.to_excel(\"Classifier_scores_f1.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export model scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove GSE object from dictionary:\n",
    "final_dict_export = {}\n",
    "for company in results_dict:\n",
    "    final_dict_export[company] = {}\n",
    "    for key in results_dict[company]:\n",
    "        if type(key) == tuple:\n",
    "            final_dict_export[company][str(key[0])+\"_\"+str(key[1])+\"_\"+str(key[2])] = results_dict[company][key].copy()\n",
    "    final_dict_export[company].pop('model', None)\n",
    "    final_dict_export[company].pop('Classifier', None)\n",
    "\n",
    "\n",
    "# # save final_dict to a json file\n",
    "# import json\n",
    "# with open('results_dict_pipelinecomparison_recall_v2.json', 'w') as file:\n",
    "#     json.dump(final_dict_export, file, indent=4)  # indent=4 is optional for pretty printing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('results_dict_pipelinecomparison_recall_f1_v3.json', 'r') as file:\n",
    "    results_dict = json.load(file)\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_dict_best = {}\n",
    "for company in results_dict:\n",
    "    results_dict_best[company] = {}\n",
    "    for model in results_dict[company]['1_1_0.01']:\n",
    "        if model == \"parallel_regressor\":\n",
    "            results_dict_best[company]['parallel_regressor'] = {'regressor' : {\"r2_score\" : -999999, \"MSE\" : 0, \"params\" : None,},\n",
    "                                                           'pipeline': {\"r2_score\" : -999999, \"MSE\" : 0, \"params\" : None,},\n",
    "                                                           'pipeline_with_correction': {\"r2_score\" : -999999, \"MSE\" : 0, \"params\" : None,},\n",
    "                                                           'pipeline_with_correction2': {\"r2_score\" : -999999, \"MSE\" : 0, \"params\" : None,}}\n",
    "        else:\n",
    "            results_dict_best[company][model] = {}\n",
    "            for input_type in results_dict[company]['1_1_0.01']['clean_regressor']:\n",
    "                results_dict_best[company][model][input_type] = {\"r2_score\" : -999999, \"MSE\" : 0, \"params\" : None,}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for paramset in results_dict[company]:\n",
    "        paramset_dict = {\"n_estimators\" : int(paramset.split(\"_\")[0]), \"max_depth\" : int(paramset.split(\"_\")[1]), \"learning_rate\" : float(paramset.split(\"_\")[2])}\n",
    "        for model in results_dict[company][paramset]:\n",
    "            if model == \"parallel_regressor\":\n",
    "                if results_dict[company][paramset][model][\"r2_score\"] > results_dict_best[company][model]['regressor'][\"r2_score\"]:\n",
    "                    results_dict_best[company][model]['regressor'][\"r2_score\"] = results_dict[company][paramset][model][\"r2_score\"]\n",
    "                    results_dict_best[company][model]['regressor']['params'] = paramset_dict\n",
    "                if results_dict[company][paramset][model][\"pipeline\"][\"r2_score\"] > results_dict_best[company][model]['pipeline'][\"r2_score\"]:\n",
    "                    results_dict_best[company][model]['pipeline'][\"r2_score\"] = results_dict[company][paramset][model][\"pipeline\"][\"r2_score\"]\n",
    "                    results_dict_best[company][model]['pipeline']['params'] = paramset_dict\n",
    "                if results_dict[company][paramset][model][\"pipeline_with_correction\"][\"r2_score\"] > results_dict_best[company][model]['pipeline_with_correction'][\"r2_score\"]:\n",
    "                    results_dict_best[company][model]['pipeline_with_correction'][\"r2_score\"] = results_dict[company][paramset][model][\"pipeline_with_correction\"][\"r2_score\"]\n",
    "                    results_dict_best[company][model]['pipeline_with_correction']['params'] = paramset_dict\n",
    "                if results_dict[company][paramset][model][\"pipeline_with_correction2\"][\"r2_score\"] > results_dict_best[company][model]['pipeline_with_correction2'][\"r2_score\"]:\n",
    "                    results_dict_best[company][model]['pipeline_with_correction2'][\"r2_score\"] = results_dict[company][paramset][model][\"pipeline_with_correction2\"][\"r2_score\"]\n",
    "                    results_dict_best[company][model]['pipeline_with_correction2']['params'] = paramset_dict\n",
    "\n",
    "\n",
    "\n",
    "            else:\n",
    "                for input_type in results_dict[company][paramset][model]:\n",
    "                    if results_dict[company][paramset][model][input_type][\"r2_score\"] > results_dict_best[company][model][input_type][\"r2_score\"]:\n",
    "                        results_dict_best[company][model][input_type][\"r2_score\"] = results_dict[company][paramset][model][input_type][\"r2_score\"]\n",
    "                        results_dict_best[company][model][input_type]['params'] = paramset_dict\n",
    "\n",
    "final_results_dict_best = {}\n",
    "for company in results_dict_best:\n",
    "    final_results_dict_best[company] = {}\n",
    "    if \"f1\" in company:\n",
    "        final_results_dict_best[company[:-3]][\"f1_optimised\"] = results_dict_best[company]\n",
    "        final_results_dict_best.pop(company)\n",
    "    else:\n",
    "        final_results_dict_best[company][\"recall_optimised\"] = results_dict_best[company]\n",
    "        final_results_dict_best[company]['volume'] = classifier_dict[company]['model'].df_input['PALLETPLAATSEN'].sum()\n",
    "        final_results_dict_best[company]['fakename'] = classifier_dict[company]['fakename']\n",
    "results_dict_best = final_results_dict_best\n",
    "\n",
    "# save final_dict to a json file\n",
    "import json\n",
    "with open('results_dict_best_v3.json', 'w') as file:\n",
    "    json.dump(results_dict_best, file, indent=4)  # indent=4 is optional for pretty printing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Scores Parallel Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results dict best 3\n",
    "import json\n",
    "with open('results_dict_best_v3.json', 'r') as file:\n",
    "    results_dict_best = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_companies = sorted(results_dict_best.items(), \n",
    "                          key=lambda x: (len(x[1]['fakename'].split()[1]), x[1]['fakename'].split()[1]))[:25]\n",
    "\n",
    "# Extract data for plotting\n",
    "data = []\n",
    "for company, details in sorted_companies:\n",
    "    fakename = details['fakename']\n",
    "    recall_score = details['recall_optimised']['parallel_regressor']['regressor']['r2_score']\n",
    "    data.append([fakename, recall_score])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Company', 'Parallel Regressor R2'])\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "width = 0.8  # the width of the bars\n",
    "x = df.index  # the label locations\n",
    "\n",
    "rects1 = ax.bar(x, df['Parallel Regressor R2'], width, label='Parallel Regressor')\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Company', fontsize=14)\n",
    "ax.set_ylabel('R2 Score', fontsize=14)\n",
    "ax.set_title('R2 Scores by Company for Recall Optimized Parallel Regressor', fontsize=18)\n",
    "ax.set_xticks(x)\n",
    "plt.yticks(fontsize=14)\n",
    "ax.set_xticklabels(df['Company'], rotation=45, fontsize=14)\n",
    "# ax.set_ylim(-0.5, 1)\n",
    "ax.legend(fontsize=14)\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_companies = sorted(results_dict_best.items(), \n",
    "                          key=lambda x: (len(x[1]['fakename'].split()[1]), x[1]['fakename'].split()[1]))\n",
    "\n",
    "# Extract data for plotting\n",
    "data = []\n",
    "for company, details in sorted_companies:\n",
    "    fakename = details['fakename']\n",
    "    volume = details['volume']\n",
    "    f1_parallel = details['f1_optimised']['parallel_regressor']['pipeline']['r2_score']\n",
    "\n",
    "    data.append([fakename, volume, f1_parallel])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Company', 'Volume','Parallel regressor'\n",
    "                                 ])\n",
    "\n",
    "\n",
    "\n",
    "# Calculating the mean of each column (excluding 'Company' and 'Volume')\n",
    "mean_values = df.drop(['Company', 'Volume'], axis=1).mean()\n",
    "\n",
    "# Calculating the weighted mean of each column (excluding 'Company' and 'Volume')\n",
    "weighted_means = (df.drop(['Company', 'Volume'], axis=1).multiply(df['Volume'], axis=0).sum() / df['Volume'].sum())\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Mean of each column:\")\n",
    "print(mean_values)\n",
    "print(\"\\nWeighted mean of each column:\")\n",
    "print(weighted_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Scores Series models with clean input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting and selecting the first 10 companies\n",
    "sorted_companies = sorted(results_dict_best.items(), \n",
    "                          key=lambda x: (len(x[1]['fakename'].split()[1]), x[1]['fakename'].split()[1]))[:10]\n",
    "\n",
    "# Extract data for plotting\n",
    "data = []\n",
    "for company, details in sorted_companies:\n",
    "    fakename = details['fakename']\n",
    "    recall_clean_clean = details['recall_optimised']['clean_regressor']['clean_input']['r2_score']\n",
    "    f1_clean_clean = details['f1_optimised']['clean_regressor']['clean_input']['r2_score']\n",
    "    recall_dirty_clean = details['recall_optimised']['dirty_regressor']['clean_input']['r2_score']\n",
    "    f1_dirty_clean = details['f1_optimised']['dirty_regressor']['clean_input']['r2_score']\n",
    "    data.append([fakename, recall_clean_clean, f1_clean_clean, recall_dirty_clean, f1_dirty_clean])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Company', 'Recall (Clean Regressor)', 'F1 (Clean Regressor)', \n",
    "                                 'Recall (Dirty Regressor)', 'F1 (Dirty Regressor)'])\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "width = 0.2  # the width of the bars\n",
    "x = np.arange(len(df))  # the label locations\n",
    "\n",
    "# ax.bar(x - width*1.5, df['Recall (Clean Regressor)'], width, label='Recall (Clean Regressor)')\n",
    "# ax.bar(x - width/2, df['F1 (Clean Regressor)'], width, label='F1 (Clean Regressor)')\n",
    "# ax.bar(x + width/2, df['Recall (Dirty Regressor)'], width, label='Recall (Dirty Regressor)')\n",
    "# ax.bar(x + width*1.5, df['F1 (Dirty Regressor)'], width, label='F1 (Dirty Regressor)')\n",
    "\n",
    "ax.bar(x - width*1.5, df['Recall (Clean Regressor)'], width, label='Clean Regressor; Classifier optimized on Recall')\n",
    "ax.bar(x - width/2, df['F1 (Clean Regressor)'], width, label='Clean Regressor; Classifier optimized on F1')\n",
    "ax.bar(x + width/2, df['Recall (Dirty Regressor)'], width, label='Dirty Regressor; Classifier optimized on Recall')\n",
    "ax.bar(x + width*1.5, df['F1 (Dirty Regressor)'], width, label='Dirty Regressor; Classifier optimized on F1')\n",
    "\n",
    "# Add labels, title, and custom x-axis tick labels with font sizes\n",
    "ax.set_xlabel('Company', fontsize=16)  # Increase font size for the x-axis label\n",
    "ax.set_ylabel('R2 Score', fontsize=16)  # Increase font size for the y-axis label\n",
    "ax.set_title('R2 Scores per Company with Known Regions', fontsize=22)  # Increase font size for the title\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df['Company'], rotation=45, fontsize=14)  # Rotate x-tick labels and set font size\n",
    "ax.set_ylim(-0.2, 1)  # Set y-axis limits\n",
    "ax.legend(fontsize=16)  # Set font size for the legend\n",
    "ax.grid(True)  # Enable grid\n",
    "plt.yticks(fontsize=14)  # Increase font size for y-ticks\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_companies = sorted(results_dict_best.items(), \n",
    "                          key=lambda x: (len(x[1]['fakename'].split()[1]), x[1]['fakename'].split()[1]))\n",
    "\n",
    "# Extract data for plotting\n",
    "data = []\n",
    "for company, details in sorted_companies:\n",
    "    fakename = details['fakename']\n",
    "    volume = details['volume']\n",
    "    recall_clean = details['recall_optimised']['clean_regressor']['clean_input']['r2_score']\n",
    "    f1_clean = details['f1_optimised']['clean_regressor']['clean_input']['r2_score']\n",
    "    recall_dirty = details['recall_optimised']['dirty_regressor']['clean_input']['r2_score']\n",
    "    f1_dirty = details['f1_optimised']['dirty_regressor']['clean_input']['r2_score']\n",
    "\n",
    "    data.append([fakename, volume, recall_clean, f1_clean, recall_dirty, f1_dirty])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Company', 'Volume','Recall (Clean Regressor)', 'F1 (Clean Regressor)', \n",
    "                                 'Recall (Dirty Regressor)', 'F1 (Dirty Regressor)',\n",
    "                                 ])\n",
    "\n",
    "\n",
    "\n",
    "# Calculating the mean of each column (excluding 'Company' and 'Volume')\n",
    "mean_values = df.drop(['Company', 'Volume'], axis=1).mean()\n",
    "\n",
    "# Calculating the weighted mean of each column (excluding 'Company' and 'Volume')\n",
    "weighted_means = (df.drop(['Company', 'Volume'], axis=1).multiply(df['Volume'], axis=0).sum() / df['Volume'].sum())\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Mean of each column:\")\n",
    "print(mean_values)\n",
    "print(\"\\nWeighted mean of each column:\")\n",
    "print(weighted_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 scores series models with dirty input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting and selecting the first 10 companies\n",
    "sorted_companies = sorted(results_dict_best.items(), \n",
    "                          key=lambda x: (len(x[1]['fakename'].split()[1]), x[1]['fakename'].split()[1]))[:10]\n",
    "\n",
    "# Extract data for plotting\n",
    "data = []\n",
    "for company, details in sorted_companies:\n",
    "    fakename = details['fakename']\n",
    "    recall_clean_clean = details['recall_optimised']['clean_regressor']['dirty_input']['r2_score']\n",
    "    f1_clean_clean = details['f1_optimised']['clean_regressor']['dirty_input']['r2_score']\n",
    "    recall_dirty_clean = details['recall_optimised']['dirty_regressor']['dirty_input']['r2_score']\n",
    "    f1_dirty_clean = details['f1_optimised']['dirty_regressor']['dirty_input']['r2_score']\n",
    "    data.append([fakename, recall_clean_clean, f1_clean_clean, recall_dirty_clean, f1_dirty_clean])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Company', 'Recall (Clean Regressor)', 'F1 (Clean Regressor)', \n",
    "                                 'Recall (Dirty Regressor)', 'F1 (Dirty Regressor)'])\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "width = 0.2  # the width of the bars\n",
    "x = np.arange(len(df))  # the label locations\n",
    "\n",
    "# ax.bar(x - width*1.5, df['Recall (Clean Regressor)'], width, label='Recall (Clean Regressor)')\n",
    "# ax.bar(x - width/2, df['F1 (Clean Regressor)'], width, label='F1 (Clean Regressor)')\n",
    "# ax.bar(x + width/2, df['Recall (Dirty Regressor)'], width, label='Recall (Dirty Regressor)')\n",
    "# ax.bar(x + width*1.5, df['F1 (Dirty Regressor)'], width, label='F1 (Dirty Regressor)')\n",
    "\n",
    "ax.bar(x - width*1.5, df['Recall (Clean Regressor)'], width, label='Clean Regressor; Classifier optimized on Recall')\n",
    "ax.bar(x - width/2, df['F1 (Clean Regressor)'], width, label='Clean Regressor; Classifier optimized on F1')\n",
    "ax.bar(x + width/2, df['Recall (Dirty Regressor)'], width, label='Dirty Regressor; Classifier optimized on Recall')\n",
    "ax.bar(x + width*1.5, df['F1 (Dirty Regressor)'], width, label='Dirty Regressor; Classifier optimized on F1')\n",
    "\n",
    "# Add labels, title, and custom x-axis tick labels with font sizes\n",
    "ax.set_xlabel('Company', fontsize=16)  # Increase font size for the x-axis label\n",
    "ax.set_ylabel('R2 Score', fontsize=16)  # Increase font size for the y-axis label\n",
    "ax.set_title('R2 Scores per Company with Unknown Regions', fontsize=22)  # Increase font size for the title\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(df['Company'], rotation=45, fontsize=14)  # Rotate x-tick labels and set font size\n",
    "ax.set_ylim(-0.2, 1)  # Set y-axis limits\n",
    "ax.legend(fontsize=16)  # Set font size for the legend\n",
    "ax.grid(True)  # Enable grid\n",
    "plt.yticks(fontsize=14)  # Increase font size for y-ticks\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_companies = sorted(results_dict_best.items(), \n",
    "                          key=lambda x: (len(x[1]['fakename'].split()[1]), x[1]['fakename'].split()[1]))\n",
    "\n",
    "# Extract data for plotting\n",
    "data = []\n",
    "for company, details in sorted_companies:\n",
    "    fakename = details['fakename']\n",
    "    volume = details['volume']\n",
    "    recall_clean = details['recall_optimised']['clean_regressor']['dirty_input']['r2_score']\n",
    "    f1_clean = details['f1_optimised']['clean_regressor']['dirty_input']['r2_score']\n",
    "    recall_dirty = details['recall_optimised']['dirty_regressor']['dirty_input']['r2_score']\n",
    "    f1_dirty = details['f1_optimised']['dirty_regressor']['dirty_input']['r2_score']\n",
    "\n",
    "    data.append([fakename, volume, recall_clean, f1_clean, recall_dirty, f1_dirty])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Company', 'Volume','Recall (Clean Regressor)', 'F1 (Clean Regressor)', \n",
    "                                 'Recall (Dirty Regressor)', 'F1 (Dirty Regressor)',\n",
    "                                 ])\n",
    "\n",
    "\n",
    "\n",
    "# Calculating the mean of each column (excluding 'Company' and 'Volume')\n",
    "mean_values = df.drop(['Company', 'Volume'], axis=1).mean()\n",
    "\n",
    "# Calculating the weighted mean of each column (excluding 'Company' and 'Volume')\n",
    "weighted_means = (df.drop(['Company', 'Volume'], axis=1).multiply(df['Volume'], axis=0).sum() / df['Volume'].sum())\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Mean of each column:\")\n",
    "print(mean_values)\n",
    "print(\"\\nWeighted mean of each column:\")\n",
    "print(weighted_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R2 Scores Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in results_dict_best.keys():\n",
    "    df = clusters_dict[company]['model'].df_input\n",
    "    df[df[\"OPDRACHTGEVERNAAM\"] == company]\n",
    "\n",
    "    results_dict_best[company]['volume'] = df[\"PALLETPLAATSEN\"].sum()\n",
    "\n",
    "# Sorting and selecting the first 10 companies\n",
    "sorted_companies = sorted(results_dict_best.items(), \n",
    "                          key=lambda x: (len(x[1]['fakename'].split()[1]), x[1]['fakename'].split()[1]))[:10]\n",
    "\n",
    "\n",
    "\n",
    "# Extract data for plotting\n",
    "data = []\n",
    "for company, details in sorted_companies:\n",
    "    fakename = details['fakename']\n",
    "    volume = details['volume']\n",
    "    recall_clean = details['recall_optimised']['clean_regressor']['pipeline']['r2_score']\n",
    "    f1_clean = details['f1_optimised']['clean_regressor']['pipeline']['r2_score']\n",
    "    recall_dirty = details['recall_optimised']['dirty_regressor']['pipeline']['r2_score']\n",
    "    f1_dirty = details['f1_optimised']['dirty_regressor']['pipeline']['r2_score']\n",
    "    recall_parallel = details['recall_optimised']['parallel_regressor']['pipeline']['r2_score']\n",
    "    f1_parallel = details['f1_optimised']['parallel_regressor']['pipeline']['r2_score']\n",
    "    data.append([fakename, volume, recall_clean, f1_clean, recall_dirty, f1_dirty, recall_parallel, f1_parallel])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Company', 'Volume','Recall (Clean Regressor)', 'F1 (Clean Regressor)', \n",
    "                                 'Recall (Dirty Regressor)', 'F1 (Dirty Regressor)',\n",
    "                                 'Recall (Parallel Regressor)', 'F1 (Parallel Regressor)'])\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "width = 0.15  # the width of the bars\n",
    "x = np.arange(len(df))  # the label locations\n",
    "\n",
    "ax.bar(x - width*2, df['Recall (Clean Regressor)'], width, label='Series pipeline with clean regressor; Recall Optimized')\n",
    "ax.bar(x - width, df['F1 (Clean Regressor)'], width, label='Series pipeline with clean regressor; F1 Optimized')\n",
    "ax.bar(x, df['Recall (Dirty Regressor)'], width, label='Series pipeline with dirty regressor; Recall Optimized')\n",
    "ax.bar(x + width, df['F1 (Dirty Regressor)'], width, label='Series pipeline with dirty regressor; F1 Optimized')\n",
    "ax.bar(x + width*2, df['Recall (Parallel Regressor)'], width, label='Parallel pipeline; Recall Optimized')\n",
    "ax.bar(x + width*3, df['F1 (Parallel Regressor)'], width, label='Parallel pipeline; F1 Optimized')\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Company', fontsize=16)\n",
    "ax.set_ylabel('R2 Score', fontsize=16)\n",
    "ax.set_title('R2 Scores per Company with Different Regressor Configurations', fontsize=20)\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(df['Company'], rotation=45, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "ax.legend(loc='lower left', fontsize=16)\n",
    "ax.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_companies = sorted(results_dict_best.items(), \n",
    "                          key=lambda x: (len(x[1]['fakename'].split()[1]), x[1]['fakename'].split()[1]))\n",
    "\n",
    "# Extract data for plotting\n",
    "data = []\n",
    "for company, details in sorted_companies:\n",
    "    fakename = details['fakename']\n",
    "    volume = details['volume']\n",
    "    recall_clean = details['recall_optimised']['clean_regressor']['pipeline']['r2_score']\n",
    "    f1_clean = details['f1_optimised']['clean_regressor']['pipeline']['r2_score']\n",
    "    recall_dirty = details['recall_optimised']['dirty_regressor']['pipeline']['r2_score']\n",
    "    f1_dirty = details['f1_optimised']['dirty_regressor']['pipeline']['r2_score']\n",
    "    recall_parallel = details['recall_optimised']['parallel_regressor']['pipeline']['r2_score']\n",
    "    f1_parallel = details['f1_optimised']['parallel_regressor']['pipeline']['r2_score']\n",
    "    data.append([fakename, volume, recall_clean, f1_clean, recall_dirty, f1_dirty, recall_parallel, f1_parallel])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Company', 'Volume','Recall (Clean Regressor)', 'F1 (Clean Regressor)', \n",
    "                                 'Recall (Dirty Regressor)', 'F1 (Dirty Regressor)',\n",
    "                                 'Recall (Parallel Regressor)', 'F1 (Parallel Regressor)'])\n",
    "\n",
    "\n",
    "\n",
    "# Calculating the mean of each column (excluding 'Company' and 'Volume')\n",
    "mean_values = df.drop(['Company', 'Volume'], axis=1).mean()\n",
    "\n",
    "# Calculating the weighted mean of each column (excluding 'Company' and 'Volume')\n",
    "weighted_means = (df.drop(['Company', 'Volume'], axis=1).multiply(df['Volume'], axis=0).sum() / df['Volume'].sum())\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Mean of each column:\")\n",
    "print(mean_values)\n",
    "print(\"\\nWeighted mean of each column:\")\n",
    "print(weighted_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample DataFrame creation (replace this with your actual DataFrame)\n",
    "# df = pd.read_csv('path_to_your_data.csv')  # Uncomment and modify this line to load your DataFrame\n",
    "\n",
    "# Generating x and y data for the graph\n",
    "x = np.arange(0.0, 1.0, 0.01)\n",
    "y = [df[df[\"Recall (Parallel Regressor)\"] > i][\"Volume\"].sum() / df[\"Volume\"].sum() for i in x]\n",
    "\n",
    "# Creating the line graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y, marker='')\n",
    "plt.title('Volume Proportion vs. Recall Threshold')\n",
    "plt.xlabel('Recall Threshold')\n",
    "plt.ylabel('Proportion of Total Volume')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting and selecting the first 10 companies\n",
    "sorted_companies = sorted(results_dict_best.items(), \n",
    "                          key=lambda x: (len(x[1]['fakename'].split()[1]), x[1]['fakename'].split()[1]))[:10]\n",
    "\n",
    "# Extract data for plotting\n",
    "data = []\n",
    "for company, details in sorted_companies:\n",
    "    fakename = details['fakename']\n",
    "    recall_dirty_pipeline = details['recall_optimised']['dirty_regressor']['pipeline']['r2_score']\n",
    "    recall_dirty_pipeline_corr = details['recall_optimised']['dirty_regressor']['pipeline_with_correction']['r2_score']\n",
    "    recall_dirty_pipeline_corr2 = details['recall_optimised']['dirty_regressor']['pipeline_with_correction2']['r2_score']\n",
    "    f1_dirty_pipeline = details['f1_optimised']['dirty_regressor']['pipeline']['r2_score']\n",
    "    f1_dirty_pipeline_corr = details['f1_optimised']['dirty_regressor']['pipeline_with_correction']['r2_score']\n",
    "    f1_dirty_pipeline_corr2 = details['f1_optimised']['dirty_regressor']['pipeline_with_correction2']['r2_score']\n",
    "\n",
    "    data.append([\n",
    "        fakename,\n",
    "        recall_dirty_pipeline, recall_dirty_pipeline_corr, recall_dirty_pipeline_corr2,\n",
    "        f1_dirty_pipeline, f1_dirty_pipeline_corr, f1_dirty_pipeline_corr2\n",
    "    ])\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data, columns=[\n",
    "    'Company', \n",
    "    'Recall - Pipeline', 'Recall - Pipeline Correction', 'Recall - Pipeline Correction2',\n",
    "    'F1 - Pipeline', 'F1 - Pipeline Correction', 'F1 - Pipeline Correction2'\n",
    "])\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "width = 0.12  # the width of the bars\n",
    "x = np.arange(len(df))  # the label locations\n",
    "\n",
    "ax.bar(x - width, df['Recall - Pipeline'], width, label='Recall - Pipeline')\n",
    "ax.bar(x, df['Recall - Pipeline Correction'], width, label='Recall - Pipeline Correction')\n",
    "ax.bar(x + width, df['Recall - Pipeline Correction2'], width, label='Recall - Pipeline Correction2')\n",
    "ax.bar(x + 2*width, df['F1 - Pipeline'], width, label='F1 - Pipeline')\n",
    "ax.bar(x + 3*width, df['F1 - Pipeline Correction'], width, label='F1 - Pipeline Correction')\n",
    "ax.bar(x + 4*width, df['F1 - Pipeline Correction2'], width, label='F1 - Pipeline Correction2')\n",
    "\n",
    "# Add some text for labels, title, and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Company')\n",
    "ax.set_ylabel('R2 Score')\n",
    "ax.set_title('R2 Scores by Company and Configuration for Dirty Regressor')\n",
    "ax.set_xticks(x + 1.5*width)\n",
    "ax.set_xticklabels(df['Company'], rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export final parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline_parameters = {}\n",
    "import json\n",
    "with open('class_parameters_recall.json', 'r') as file:\n",
    "    class_parameters = json.load(file)\n",
    "\n",
    "\n",
    "with open('results_dict_best_v3.json', 'r') as file:\n",
    "    regg_parameters = json.load(file)\n",
    "\n",
    "for company in class_parameters:\n",
    "    final_pipeline_parameters[company] = {}\n",
    "    final_pipeline_parameters[company]['fakename'] = class_parameters[company]['fakename'] \n",
    "    final_pipeline_parameters[company]['n_clusters'] = class_parameters[company]['nclusters']\n",
    "\n",
    "    final_pipeline_parameters[company]['class_parameters'] = {}\n",
    "    final_pipeline_parameters[company]['class_parameters']['learning_rate'] = float(class_parameters[company]['params']['learning_rate'])\n",
    "    final_pipeline_parameters[company]['class_parameters']['max_depth'] = int(class_parameters[company]['params']['max_depth'])\n",
    "    final_pipeline_parameters[company]['class_parameters']['n_estimators'] = int(class_parameters[company]['params']['n_estimators'])\n",
    "\n",
    "    final_pipeline_parameters[company]['regressor_parameters'] = {}\n",
    "    final_pipeline_parameters[company]['regressor_parameters']['learning_rate'] = float(regg_parameters[company]['recall_optimised']['parallel_regressor']['pipeline']['params']['learning_rate'])\n",
    "    final_pipeline_parameters[company]['regressor_parameters']['max_depth'] = int(regg_parameters[company]['recall_optimised']['parallel_regressor']['pipeline']['params']['max_depth'])\n",
    "    final_pipeline_parameters[company]['regressor_parameters']['n_estimators'] = int(regg_parameters[company]['recall_optimised']['parallel_regressor']['pipeline']['params']['n_estimators'])\n",
    "\n",
    "# save final_dict to a json file\n",
    "\n",
    "with open('final_pipeline_parameters.json', 'w') as file:\n",
    "    json.dump(final_pipeline_parameters, file, indent=4)  # indent=4 is optional for pretty printing\n",
    "final_pipeline_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regg_parameters[company]['recall_optimised']['parallel_regressor']['pipeline']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print regressor pipeline scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for company in results_dict:\n",
    "    print(company)\n",
    "    print(\"====================================\")\n",
    "    best_r2_clean = -9999\n",
    "    best_r2_dirty = -9999\n",
    "    best_r2_paralel = -9999 \n",
    "    for paramset in results_dict[company]:\n",
    "        if paramset == \"classifier\":\n",
    "            continue\n",
    "        if results_dict[company][paramset][\"clean_regressor\"]['pipeline'][\"r2_score\"] > best_r2_clean:\n",
    "            best_r2_clean = results_dict[company][paramset][\"clean_regressor\"]['pipeline'][\"r2_score\"]\n",
    "            best_params_clean = paramset\n",
    "        if results_dict[company][paramset][\"dirty_regressor\"]['pipeline'][\"r2_score\"] > best_r2_dirty:\n",
    "            best_r2_dirty = results_dict[company][paramset][\"dirty_regressor\"]['pipeline'][\"r2_score\"]\n",
    "            best_params_dirty = paramset\n",
    "        if results_dict[company][paramset][\"parallel_regressor\"]['pipeline'][\"r2_score\"] > best_r2_paralel:\n",
    "            best_r2_paralel = results_dict[company][paramset][\"parallel_regressor\"]['pipeline'][\"r2_score\"]\n",
    "            best_params_paralel = paramset\n",
    "    print(f\"Best clean regressor: {best_r2_clean} with parameters: {best_params_clean}\")\n",
    "    print(f\"Best dirty regressor: {best_r2_dirty} with parameters: {best_params_dirty}\")\n",
    "    print(f\"Best parallel regressor: {best_r2_paralel} with parameters: {best_params_paralel}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Regressor scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data storage\n",
    "data = {\n",
    "    'Real Company': [],\n",
    "    'Company': [],\n",
    "    'Clean Regressor': [],\n",
    "    'Dirty Regressor': [],\n",
    "    'Parallel Regressor': []\n",
    "}\n",
    "\n",
    "# Extract data\n",
    "for company, metrics in results_dict.items():\n",
    "    best_r2_clean = -9999\n",
    "    best_r2_dirty = -9999\n",
    "    best_r2_parallel = -9999\n",
    "    \n",
    "    for paramset in metrics:\n",
    "        if paramset == \"classifier\":\n",
    "            continue\n",
    "        r2_clean = metrics[paramset][\"clean_regressor\"][\"r2_score\"]\n",
    "        r2_dirty = metrics[paramset][\"dirty_regressor\"][\"r2_score\"]\n",
    "        r2_parallel = metrics[paramset][\"paralel_regressor\"][\"r2_score\"]\n",
    "\n",
    "        if r2_clean > best_r2_clean:\n",
    "            best_r2_clean = r2_clean\n",
    "        if r2_dirty > best_r2_dirty:\n",
    "            best_r2_dirty = r2_dirty\n",
    "        if r2_parallel > best_r2_parallel:\n",
    "            best_r2_parallel = r2_parallel\n",
    "    data['Real Company'].append(company)\n",
    "    data['Company'].append(clusters_dict[company]['fakename'])\n",
    "    data['Clean Regressor'].append(best_r2_clean)\n",
    "    data['Dirty Regressor'].append(best_r2_dirty)\n",
    "    data['Parallel Regressor'].append(best_r2_parallel)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_scores = pd.DataFrame(data)\n",
    "# Define a function to plot in chunks\n",
    "def plot_grouped_bars(dataframe, chunk_size):\n",
    "    chunks = len(dataframe) // chunk_size + (1 if len(dataframe) % chunk_size > 0 else 0)\n",
    "    \n",
    "    for i in range(chunks):\n",
    "        chunk = dataframe.iloc[i * chunk_size:(i + 1) * chunk_size]\n",
    "        ax = chunk.plot(kind='bar', x='Company', figsize=(12, 8), title=f'R2 Scores for Regressor Models for Companies {i * chunk_size + 1} to {(i + 1) * chunk_size}')\n",
    "        ax.set_xlabel('Company')\n",
    "        ax.set_ylabel('R2 Score')\n",
    "        ax.grid(True)\n",
    "        plt.legend(title='Regressor Type')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Plotting in groups of 10\n",
    "plot_grouped_bars(df_scores, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean scores for Clean Regressor: {df_scores['Clean Regressor'].mean()}\")\n",
    "print(f\"Mean scores for Dirty Regressor: {df_scores['Dirty Regressor'].mean()}\")\n",
    "print(f\"Mean scores for Parallel Regressor: {df_scores['Parallel Regressor'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores\n",
    "#export to XLSX\n",
    "df_scores.to_excel(\"Regressor_scores.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Regressor Scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean vs dirty trained regressor with clean input vs dirty input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize data storage\n",
    "data = {\n",
    "    'Company': [],\n",
    "    'Parallel (Recall)': [],\n",
    "    }\n",
    "\n",
    "# Define a variable to select the metric type\n",
    "metric_type = None  # You can change this to compare various types\n",
    "\n",
    "# Extract data\n",
    "for company, metrics_recall in results_dict_recall.items():\n",
    "    metrics_f1 = results_dict_f1[company]\n",
    "    \n",
    "    best_r2_parallel_recall = -9999\n",
    "    \n",
    "    for paramset in metrics_recall:\n",
    "        if paramset == \"classifier\":\n",
    "            continue\n",
    "\n",
    "        r2_parallel_recall = metrics_recall[paramset][\"paralel_regressor\"][\"r2_score\"]\n",
    "        \n",
    "        if r2_parallel_recall > best_r2_parallel_recall:\n",
    "            best_r2_parallel_recall = r2_parallel_recall\n",
    "   \n",
    "\n",
    "    data['Company'].append(clusters_dict[company]['fakename'])\n",
    "    data['Parallel (Recall)'].append(best_r2_parallel_recall)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "df_scores = pd.DataFrame(data)\n",
    "\n",
    "# Define a function to plot in chunks\n",
    "def plot_grouped_bars(dataframe, chunk_size, title=None, max_plots=None):\n",
    "    chunks = len(dataframe) // chunk_size + (1 if len(dataframe) % chunk_size > 0 else 0)\n",
    "    \n",
    "    for i in range(chunks):\n",
    "        if max_plots is not None and i >= max_plots:\n",
    "            break\n",
    "        chunk = dataframe.iloc[i * chunk_size:(i + 1) * chunk_size]\n",
    "        if title is None:\n",
    "            title =f'R2 Scores for regressor for Companies {i * chunk_size + 1} to {(i + 1) * chunk_size}'\n",
    "        ax = chunk.plot(kind='bar', x='Company', figsize=(12, 8), title=title)\n",
    "        ax.set_xlabel('Company')\n",
    "        ax.set_ylabel('R2 Score')\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        plt.legend(title='Regressor Type')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(f\"Parallel Regressor: {df_scores['Parallel (Recall)'].mean()}\")\n",
    "print(f\"Parallel Regressor score non negative: {df_scores[df_scores['Parallel (Recall)'] >= 0]['Parallel (Recall)'].mean()}\")\n",
    "\n",
    "# Plotting in groups of 10\n",
    "plot_grouped_bars(df_scores[['Company', 'Parallel (Recall)']], 26,\n",
    "                  \"R2 score for companies A thru Z for parallel regressor\", 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor:\n",
    "    def __init__(self, df_orders, pc=None):\n",
    "        if pc is None:\n",
    "            pc = PC()\n",
    "        else:\n",
    "            self.pc = pc\n",
    "        self.pipelines_list = {}\n",
    "        self.GSE_list = {}\n",
    "        self.df_orders = df_orders\n",
    "\n",
    "    def add_pipeline(self, company, parameters):\n",
    "        self.pipelines_list[company] = pipeline\n",
    "\n",
    "    def add_GSE(self, company, n_clusters):\n",
    "        df_temp = self.df_orders[self.df_orders['OPDRACHTGEVERNAAM'] == company]\n",
    "        self.GSE_list[company] = GeoSpatialEncoder(self.pc)\n",
    "        self.GSE_list[company].set_verbose(False)\n",
    "        self.GSE_list[company].set_input_df(df_temp)\n",
    "        self.GSE_list[company].clean_input_df()\n",
    "        self.GSE_list[company].train_kmeans(n_clusters, 'SHIPMENT_COUNT')\n",
    "    \n",
    "    def predict_order_row(self, row):\n",
    "        # Generate input row\n",
    "        comp = row[\"OPDRACHTGEVERNAAM\"]\n",
    "\n",
    "        \n",
    "    \n",
    "    def create_d_orders_from_a_row(self, df):\n",
    "        # Generate input row\n",
    "        pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize data storage\n",
    "data = {\n",
    "    'Company': [],\n",
    "    'Clean Regressor Clean Input (Recall)': [],\n",
    "    'Dirty Regressor Clean Input (Recall)': [],\n",
    "    'Clean Regressor Dirty Input (Recall)': [],\n",
    "    'Dirty Regressor Dirty Input (Recall)': [],\n",
    "    \n",
    "    'Clean Regressor Clean Input (F1)': [],\n",
    "    'Dirty Regressor Clean Input (F1)': [],\n",
    "    'Clean Regressor Dirty Input (F1)': [],\n",
    "    'Dirty Regressor Dirty Input (F1)': []\n",
    "    }\n",
    "\n",
    "# Define a variable to select the metric type\n",
    "metric_type = None  # You can change this to compare various types\n",
    "\n",
    "# Extract data\n",
    "for company, metrics_recall in results_dict_recall.items():\n",
    "    metrics_f1 = results_dict_f1[company]\n",
    "    \n",
    "    best_r2_cleanmodel_recall_clean_input = -9999\n",
    "    best_r2_dirtymodel_recall_clean_input = -9999\n",
    "    best_r2_cleanmodel_recall_dirty_input = -9999\n",
    "    best_r2_dirtymodel_recall_dirty_input = -9999\n",
    "\n",
    "    best_r2_cleanmodel_f1_clean_input = -9999\n",
    "    best_r2_dirtymodel_f1_clean_input = -9999\n",
    "    best_r2_cleanmodel_f1_dirty_input = -9999\n",
    "    best_r2_dirtymodel_f1_dirty_input = -9999\n",
    "    \n",
    "    for paramset in metrics_recall:\n",
    "        if paramset == \"classifier\":\n",
    "            continue\n",
    "\n",
    "        r2_cleanmodel_recall_clean_input = metrics_recall[paramset][\"clean_regressor\"]['clean_input'][\"r2_score\"]\n",
    "        r2_dirtymodel_recall_clean_input = metrics_recall[paramset][\"dirty_regressor\"]['clean_input'][\"r2_score\"]\n",
    "        r2_cleanmodel_recall_dirty_input = metrics_recall[paramset][\"clean_regressor\"]['dirty_input'][\"r2_score\"]\n",
    "        r2_dirtymodel_recall_dirty_input = metrics_recall[paramset][\"dirty_regressor\"]['dirty_input'][\"r2_score\"]\n",
    "\n",
    "        \n",
    "        r2_dirtymodel_f1_clean_input = metrics_f1[paramset][\"dirty_regressor\"]['clean_input'][\"r2_score\"]\n",
    "        r2_cleanmodel_f1_dirty_input = metrics_f1[paramset][\"clean_regressor\"]['dirty_input'][\"r2_score\"]\n",
    "        r2_dirtymodel_f1_dirty_input = metrics_f1[paramset][\"dirty_regressor\"]['dirty_input'][\"r2_score\"]\n",
    "        r2_cleanmodel_f1_clean_input = metrics_f1[paramset][\"clean_regressor\"]['clean_input'][\"r2_score\"]\n",
    "\n",
    "\n",
    "        if r2_cleanmodel_recall_clean_input > best_r2_cleanmodel_recall_clean_input:\n",
    "            best_r2_cleanmodel_recall_clean_input = r2_cleanmodel_recall_clean_input\n",
    "        if r2_dirtymodel_recall_clean_input > best_r2_dirtymodel_recall_clean_input:\n",
    "            best_r2_dirtymodel_recall_clean_input = r2_dirtymodel_recall_clean_input\n",
    "        if r2_cleanmodel_recall_dirty_input > best_r2_cleanmodel_recall_dirty_input:\n",
    "            best_r2_cleanmodel_recall_dirty_input = r2_cleanmodel_recall_dirty_input\n",
    "        if r2_dirtymodel_recall_dirty_input > best_r2_dirtymodel_recall_dirty_input:\n",
    "            best_r2_dirtymodel_recall_dirty_input = r2_dirtymodel_recall_dirty_input\n",
    "\n",
    "        if r2_cleanmodel_f1_clean_input > best_r2_cleanmodel_f1_clean_input:\n",
    "            best_r2_cleanmodel_f1_clean_input = r2_cleanmodel_f1_clean_input\n",
    "        if r2_dirtymodel_f1_clean_input > best_r2_dirtymodel_f1_clean_input:\n",
    "            best_r2_dirtymodel_f1_clean_input = r2_dirtymodel_f1_clean_input\n",
    "        if r2_cleanmodel_f1_dirty_input > best_r2_cleanmodel_f1_dirty_input:\n",
    "            best_r2_cleanmodel_f1_dirty_input = r2_cleanmodel_f1_dirty_input\n",
    "        if r2_dirtymodel_f1_dirty_input > best_r2_dirtymodel_f1_dirty_input:\n",
    "            best_r2_dirtymodel_f1_dirty_input = r2_dirtymodel_f1_dirty_input\n",
    "\n",
    "\n",
    "    data['Company'].append(clusters_dict[company]['fakename'])\n",
    "    data['Clean Regressor Clean Input (Recall)'].append(best_r2_cleanmodel_recall_clean_input)\n",
    "    data['Dirty Regressor Clean Input (Recall)'].append(best_r2_dirtymodel_recall_clean_input)\n",
    "    data['Clean Regressor Dirty Input (Recall)'].append(best_r2_cleanmodel_recall_dirty_input)\n",
    "    data['Dirty Regressor Dirty Input (Recall)'].append(best_r2_dirtymodel_recall_dirty_input)\n",
    "\n",
    "    data['Clean Regressor Clean Input (F1)'].append(best_r2_cleanmodel_f1_clean_input)\n",
    "    data['Dirty Regressor Clean Input (F1)'].append(best_r2_dirtymodel_f1_clean_input)\n",
    "    data['Clean Regressor Dirty Input (F1)'].append(best_r2_cleanmodel_f1_dirty_input)\n",
    "    data['Dirty Regressor Dirty Input (F1)'].append(best_r2_dirtymodel_f1_dirty_input)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_scores = pd.DataFrame(data)\n",
    "\n",
    "# Define a function to plot in chunks\n",
    "def plot_grouped_bars(dataframe, chunk_size, title=None, max_plots=None):\n",
    "    chunks = len(dataframe) // chunk_size + (1 if len(dataframe) % chunk_size > 0 else 0)\n",
    "    \n",
    "    for i in range(chunks):\n",
    "        if max_plots is not None and i >= max_plots:\n",
    "            break\n",
    "        chunk = dataframe.iloc[i * chunk_size:(i + 1) * chunk_size]\n",
    "        if title is None:\n",
    "            title =f'R2 Scores for regressor for Companies {i * chunk_size + 1} to {(i + 1) * chunk_size}'\n",
    "        ax = chunk.plot(kind='bar', x='Company', figsize=(12, 8), title=title)\n",
    "        ax.set_xlabel('Company')\n",
    "        ax.set_ylabel('R2 Score')\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        plt.legend(title='Regressor Type')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(f\"Clean Regressor Clean Input (Recall): {df_scores['Clean Regressor Clean Input (Recall)'].mean()}\")\n",
    "print(f\"Dirty Regressor Clean Input (Recall): {df_scores['Dirty Regressor Clean Input (Recall)'].mean()}\")\n",
    "print(f\"Clean Regressor Dirty Input (Recall): {df_scores['Clean Regressor Dirty Input (Recall)'].mean()}\")\n",
    "print(f\"Dirty Regressor Dirty Input (Recall): {df_scores['Dirty Regressor Dirty Input (Recall)'].mean()}\")\n",
    "print(f\"Clean Regressor Clean Input (F1): {df_scores['Clean Regressor Clean Input (F1)'].mean()}\")\n",
    "print(f\"Dirty Regressor Clean Input (F1): {df_scores['Dirty Regressor Clean Input (F1)'].mean()}\")\n",
    "print(f\"Clean Regressor Dirty Input (F1): {df_scores['Clean Regressor Dirty Input (F1)'].mean()}\")\n",
    "print(f\"Dirty Regressor Dirty Input (F1): {df_scores['Dirty Regressor Dirty Input (F1)'].mean()}\")\n",
    "\n",
    "\n",
    "\n",
    "# Plotting in groups of 10\n",
    "plot_grouped_bars(df_scores[['Company', 'Clean Regressor Clean Input (Recall)', 'Dirty Regressor Clean Input (Recall)', 'Clean Regressor Clean Input (F1)', 'Dirty Regressor Clean Input (F1)']], 10,\n",
    "                  \"R2 score for companies A thru J with known testing regions\", 1)\n",
    "\n",
    "# Plotting in groups of 10\n",
    "plot_grouped_bars(df_scores[['Company', 'Clean Regressor Dirty Input (Recall)', 'Dirty Regressor Dirty Input (Recall)', 'Clean Regressor Dirty Input (F1)', 'Dirty Regressor Dirty Input (F1)']], 10,\n",
    "                  \"R2 score for companies A thru J with predicted testing regions\", 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data storage\n",
    "data = {\n",
    "    'Company': [],\n",
    "    'Clean Regressor': [],\n",
    "    'Dirty Regressor': [],\n",
    "    'Parallel Regressor': []\n",
    "}\n",
    "\n",
    "# Extract data\n",
    "for company, metrics in results_dict.items():\n",
    "    best_r2_clean = -9999\n",
    "    best_r2_dirty = -9999\n",
    "    best_r2_parallel = -9999\n",
    "    \n",
    "    for paramset in metrics:\n",
    "        if paramset == \"classifier\":\n",
    "            continue\n",
    "        r2_clean = metrics[paramset][\"clean_regressor\"]['pipeline'][\"r2_score\"]\n",
    "        r2_dirty = metrics[paramset][\"dirty_regressor\"]['pipeline'][\"r2_score\"]\n",
    "        r2_parallel = metrics[paramset][\"paralel_regressor\"]['pipeline'][\"r2_score\"]\n",
    "\n",
    "        if r2_clean > best_r2_clean:\n",
    "            best_r2_clean = r2_clean\n",
    "        if r2_dirty > best_r2_dirty:\n",
    "            best_r2_dirty = r2_dirty\n",
    "        if r2_parallel > best_r2_parallel:\n",
    "            best_r2_parallel = r2_parallel\n",
    "\n",
    "    data['Company'].append(company)\n",
    "    data['Clean Regressor'].append(best_r2_clean)\n",
    "    data['Dirty Regressor'].append(best_r2_dirty)\n",
    "    data['Parallel Regressor'].append(best_r2_parallel)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_scores = pd.DataFrame(data)\n",
    "# Define a function to plot in chunks\n",
    "def plot_grouped_bars(dataframe, chunk_size):\n",
    "    chunks = len(dataframe) // chunk_size + (1 if len(dataframe) % chunk_size > 0 else 0)\n",
    "    \n",
    "    for i in range(chunks):\n",
    "        chunk = dataframe.iloc[i * chunk_size:(i + 1) * chunk_size]\n",
    "        ax = chunk.plot(kind='bar', x='Company', figsize=(12, 8), title=f'R2 Scores for Pipeline for Companies {i * chunk_size + 1} to {(i + 1) * chunk_size}')\n",
    "        ax.set_xlabel('Company')\n",
    "        ax.set_ylabel('R2 Score')\n",
    "        ax.grid(True)\n",
    "        plt.legend(title='Regressor Type')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Plotting in groups of 10\n",
    "plot_grouped_bars(df_scores, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare f1 with recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize data storage\n",
    "data = {\n",
    "    'Company': [],\n",
    "    'PALLETPLAATSEN': [],\n",
    "    'Clean Regressor (Recall)': [],\n",
    "    'Dirty Regressor (Recall)': [],\n",
    "    'Parallel Regressor (Recall)': [],\n",
    "    'Clean Regressor (F1)': [],\n",
    "    'Dirty Regressor (F1)': [],\n",
    "    'Parallel Regressor (F1)': []\n",
    "}\n",
    "\n",
    "# Define a variable to select the metric type\n",
    "metric_type = 'pipeline'  # You can change this to compare various types\n",
    "\n",
    "# Extract data\n",
    "for company, metrics_recall in results_dict_recall.items():\n",
    "    metrics_f1 = results_dict[company]\n",
    "    \n",
    "    best_r2_clean_recall = -9999\n",
    "    best_r2_dirty_recall = -9999\n",
    "    best_r2_parallel_recall = -9999\n",
    "    best_r2_clean_f1 = -9999\n",
    "    best_r2_dirty_f1 = -9999\n",
    "    best_r2_parallel_f1 = -9999\n",
    "    \n",
    "    for paramset in metrics_recall:\n",
    "        if paramset == \"classifier\":\n",
    "            continue\n",
    "        \n",
    "        r2_clean_recall = metrics_recall[paramset][\"clean_regressor\"][metric_type][\"r2_score\"]\n",
    "        r2_dirty_recall = metrics_recall[paramset][\"dirty_regressor\"][metric_type][\"r2_score\"]\n",
    "        r2_parallel_recall = metrics_recall[paramset][\"paralel_regressor\"][metric_type][\"r2_score\"]\n",
    "        \n",
    "        r2_clean_f1 = metrics_f1[paramset][\"clean_regressor\"][metric_type][\"r2_score\"]\n",
    "        r2_dirty_f1 = metrics_f1[paramset][\"dirty_regressor\"][metric_type][\"r2_score\"]\n",
    "        r2_parallel_f1 = metrics_f1[paramset][\"paralel_regressor\"][metric_type][\"r2_score\"]\n",
    "\n",
    "        if r2_clean_recall > best_r2_clean_recall:\n",
    "            best_r2_clean_recall = r2_clean_recall\n",
    "        if r2_dirty_recall > best_r2_dirty_recall:\n",
    "            best_r2_dirty_recall = r2_dirty_recall\n",
    "        if r2_parallel_recall > best_r2_parallel_recall:\n",
    "            best_r2_parallel_recall = r2_parallel_recall\n",
    "\n",
    "        if r2_clean_f1 > best_r2_clean_f1:\n",
    "            best_r2_clean_f1 = r2_clean_f1\n",
    "        if r2_dirty_f1 > best_r2_dirty_f1:\n",
    "            best_r2_dirty_f1 = r2_dirty_f1\n",
    "        if r2_parallel_f1 > best_r2_parallel_f1:\n",
    "            best_r2_parallel_f1 = r2_parallel_f1\n",
    "\n",
    "    data['Company'].append(company)\n",
    "    data['PALLETPLAATSEN'].append(df_orders[df_orders['OPDRACHTGEVERNAAM'] == company]['PALLETPLAATSEN'].sum())\n",
    "    data['Clean Regressor (Recall)'].append(best_r2_clean_recall)\n",
    "    data['Dirty Regressor (Recall)'].append(best_r2_dirty_recall)\n",
    "    data['Parallel Regressor (Recall)'].append(best_r2_parallel_recall)\n",
    "    data['Clean Regressor (F1)'].append(best_r2_clean_f1)\n",
    "    data['Dirty Regressor (F1)'].append(best_r2_dirty_f1)\n",
    "    data['Parallel Regressor (F1)'].append(best_r2_parallel_f1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_scores = pd.DataFrame(data)\n",
    "\n",
    "# Define a function to plot in chunks\n",
    "def plot_grouped_bars(dataframe, chunk_size):\n",
    "    dataframe = dataframe.copy().drop(columns='PALLETPLAATSEN')\n",
    "    chunks = len(dataframe) // chunk_size + (1 if len(dataframe) % chunk_size > 0 else 0)\n",
    "    \n",
    "    for i in range(chunks):\n",
    "        chunk = dataframe.iloc[i * chunk_size:(i + 1) * chunk_size]\n",
    "        ax = chunk.plot(kind='bar', x='Company', figsize=(12, 8), title=f'R2 Scores for {metric_type.capitalize()} for Companies {i * chunk_size + 1} to {(i + 1) * chunk_size}')\n",
    "        ax.set_xlabel('Company')\n",
    "        ax.set_ylabel('R2 Score')\n",
    "        ax.grid(True)\n",
    "        plt.legend(title='Regressor Type')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "print(\"====================================\")\n",
    "print(\"Normal\")\n",
    "print(\"Taking all values\")\n",
    "print(f\"Mean scores for Clean Regressor (Recall): {df_scores['Clean Regressor (Recall)'].mean()}\")\n",
    "print(f\"Mean scores for Dirty Regressor (Recall): {df_scores['Dirty Regressor (Recall)'].mean()}\")\n",
    "print(f\"Mean scores for Parallel Regressor (Recall): {df_scores['Parallel Regressor (Recall)'].mean()}\")\n",
    "print(f\"Mean scores for Clean Regressor (F1): {df_scores['Clean Regressor (F1)'].mean()}\")\n",
    "print(f\"Mean scores for Dirty Regressor (F1): {df_scores['Dirty Regressor (F1)'].mean()}\")\n",
    "print(f\"Mean scores for Parallel Regressor (F1): {df_scores['Parallel Regressor (F1)'].mean()}\")\n",
    "\n",
    "print(\"Taking non negative values\")\n",
    "print(f\"Mean scores for Clean Regressor (Recall): {df_scores[df_scores['Clean Regressor (Recall)'] >= 0]['Clean Regressor (Recall)'].mean()}\")\n",
    "print(f\"Mean scores for Dirty Regressor (Recall): {df_scores[df_scores['Dirty Regressor (Recall)'] >= 0]['Dirty Regressor (Recall)'].mean()}\")\n",
    "print(f\"Mean scores for Parallel Regressor (Recall): {df_scores[df_scores['Parallel Regressor (Recall)'] >= 0]['Parallel Regressor (Recall)'].mean()}\")\n",
    "print(f\"Mean scores for Clean Regressor (F1): {df_scores[df_scores['Clean Regressor (F1)'] >= 0]['Clean Regressor (F1)'].mean()}\")\n",
    "print(f\"Mean scores for Dirty Regressor (F1): {df_scores[df_scores['Dirty Regressor (F1)'] >= 0]['Dirty Regressor (F1)'].mean()}\")\n",
    "print(f\"Mean scores for Parallel Regressor (F1): {df_scores[df_scores['Parallel Regressor (F1)'] >= 0]['Parallel Regressor (F1)'].mean()}\")\n",
    "print(\"====================================\")\n",
    "df_scores[\"Weighed Clean Regressor (Recall)\"] = df_scores['Clean Regressor (Recall)'] * df_scores['PALLETPLAATSEN'] / df_scores['PALLETPLAATSEN'].sum()\n",
    "df_scores[\"Weighed Dirty Regressor (Recall)\"] = df_scores['Dirty Regressor (Recall)'] * df_scores['PALLETPLAATSEN'] / df_scores['PALLETPLAATSEN'].sum()\n",
    "df_scores[\"Weighed Parallel Regressor (Recall)\"] = df_scores['Parallel Regressor (Recall)'] * df_scores['PALLETPLAATSEN'] / df_scores['PALLETPLAATSEN'].sum()\n",
    "df_scores[\"Weighed Clean Regressor (F1)\"] = df_scores['Clean Regressor (F1)'] * df_scores['PALLETPLAATSEN'] / df_scores['PALLETPLAATSEN'].sum()\n",
    "df_scores[\"Weighed Dirty Regressor (F1)\"] = df_scores['Dirty Regressor (F1)'] * df_scores['PALLETPLAATSEN'] / df_scores['PALLETPLAATSEN'].sum()\n",
    "df_scores[\"Weighed Parallel Regressor (F1)\"] = df_scores['Parallel Regressor (F1)'] * df_scores['PALLETPLAATSEN'] / df_scores['PALLETPLAATSEN'].sum()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Weighing each companies score by the amount of palletplaatsen\")\n",
    "print(\"Taking all values\")\n",
    "print(f\"Mean scores for Clean Regressor (Recall):{df_scores['Weighed Clean Regressor (Recall)'].sum()}\")\n",
    "print(f\"Mean scores for Dirty Regressor (Recall): {df_scores['Weighed Dirty Regressor (Recall)'].sum()}\")\n",
    "print(f\"Mean scores for Parallel Regressor (Recall): {df_scores['Weighed Parallel Regressor (Recall)'].sum()}\")\n",
    "print(f\"Mean scores for Clean Regressor (F1): {df_scores['Weighed Clean Regressor (F1)'].sum()}\")\n",
    "print(f\"Mean scores for Dirty Regressor (F1): {df_scores['Weighed Dirty Regressor (F1)'].sum()}\")\n",
    "print(f\"Mean scores for Parallel Regressor (F1): {df_scores['Weighed Parallel Regressor (F1)'].sum()}\")\n",
    "print(\"====================================\")\n",
    "\n",
    "\n",
    "# Plotting in groups of 10\n",
    "plot_grouped_bars(df_scores[[column for column in df_scores.columns if \"Weighed\" not in column]], 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize data storage\n",
    "data = {\n",
    "    'Company': [],\n",
    "    'Clean Regressor (Recall)': [],\n",
    "    'Dirty Regressor (Recall)': [],\n",
    "    'Parallel Regressor (Recall)': [],\n",
    "    'Clean Regressor (F1)': [],\n",
    "    'Dirty Regressor (F1)': [],\n",
    "    'Parallel Regressor (F1)': []\n",
    "}\n",
    "\n",
    "# Define a variable to select the metric type\n",
    "metric_type = None  # You can change this to compare various types\n",
    "\n",
    "# Extract data\n",
    "for company, metrics_recall in results_dict_recall.items():\n",
    "    metrics_f1 = results_dict_f1[company]\n",
    "    \n",
    "    best_r2_clean_recall = -9999\n",
    "    best_r2_dirty_recall = -9999\n",
    "    best_r2_parallel_recall = -9999\n",
    "    best_r2_clean_f1 = -9999\n",
    "    best_r2_dirty_f1 = -9999\n",
    "    best_r2_parallel_f1 = -9999\n",
    "    \n",
    "    for paramset in metrics_recall:\n",
    "        if paramset == \"classifier\":\n",
    "            continue\n",
    "\n",
    "\n",
    "        r2_clean_recall = metrics_recall[paramset][\"clean_regressor\"]['dirty_input'][\"r2_score\"]\n",
    "        r2_dirty_recall = metrics_recall[paramset][\"dirty_regressor\"]['dirty_input'][\"r2_score\"]\n",
    "        r2_parallel_recall = metrics_recall[paramset][\"paralel_regressor\"][\"r2_score\"]\n",
    "        \n",
    "        r2_clean_f1 = metrics_f1[paramset][\"clean_regressor\"]['dirty_input'][\"r2_score\"]\n",
    "        r2_dirty_f1 = metrics_f1[paramset][\"dirty_regressor\"]['dirty_input'][\"r2_score\"]\n",
    "        r2_parallel_f1 = metrics_f1[paramset][\"paralel_regressor\"][\"r2_score\"]\n",
    "\n",
    "        if r2_clean_recall > best_r2_clean_recall:\n",
    "            best_r2_clean_recall = r2_clean_recall\n",
    "        if r2_dirty_recall > best_r2_dirty_recall:\n",
    "            best_r2_dirty_recall = r2_dirty_recall\n",
    "        if r2_parallel_recall > best_r2_parallel_recall:\n",
    "            best_r2_parallel_recall = r2_parallel_recall\n",
    "\n",
    "        if r2_clean_f1 > best_r2_clean_f1:\n",
    "            best_r2_clean_f1 = r2_clean_f1\n",
    "        if r2_dirty_f1 > best_r2_dirty_f1:\n",
    "            best_r2_dirty_f1 = r2_dirty_f1\n",
    "        if r2_parallel_f1 > best_r2_parallel_f1:\n",
    "            best_r2_parallel_f1 = r2_parallel_f1\n",
    "\n",
    "    data['Company'].append(company)\n",
    "    data['Clean Regressor (Recall)'].append(best_r2_clean_recall)\n",
    "    data['Dirty Regressor (Recall)'].append(best_r2_dirty_recall)\n",
    "    data['Parallel Regressor (Recall)'].append(best_r2_parallel_recall)\n",
    "    data['Clean Regressor (F1)'].append(best_r2_clean_f1)\n",
    "    data['Dirty Regressor (F1)'].append(best_r2_dirty_f1)\n",
    "    data['Parallel Regressor (F1)'].append(best_r2_parallel_f1)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_scores = pd.DataFrame(data)\n",
    "\n",
    "# Define a function to plot in chunks\n",
    "def plot_grouped_bars(dataframe, chunk_size):\n",
    "    chunks = len(dataframe) // chunk_size + (1 if len(dataframe) % chunk_size > 0 else 0)\n",
    "    \n",
    "    for i in range(chunks):\n",
    "        chunk = dataframe.iloc[i * chunk_size:(i + 1) * chunk_size]\n",
    "        ax = chunk.plot(kind='bar', x='Company', figsize=(12, 8), title=f'R2 Scores for regressor for Companies {i * chunk_size + 1} to {(i + 1) * chunk_size}')\n",
    "        ax.set_xlabel('Company')\n",
    "        ax.set_ylabel('R2 Score')\n",
    "        ax.grid(True)\n",
    "        ax.set_ylim(-1, 1)\n",
    "        plt.legend(title='Regressor Type')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(f\"Mean R2 scores for Clean Regressor (Recall): {df_scores['Clean Regressor (Recall)'].mean()}\")\n",
    "print(f\"Mean R2 scores for Dirty Regressor (Recall): {df_scores['Dirty Regressor (Recall)'].mean()}\")\n",
    "print(f\"Mean R2 scores for Clean Regressor (F1): {df_scores['Clean Regressor (F1)'].mean()}\")\n",
    "print(f\"Mean R2 scores for Dirty Regressor (F1): {df_scores['Dirty Regressor (F1)'].mean()}\")\n",
    "\n",
    "# Plotting in groups of 10\n",
    "plot_grouped_bars(df_scores[['Company', 'Clean Regressor (Recall)', 'Dirty Regressor (Recall)', 'Clean Regressor (F1)', 'Dirty Regressor (F1)']], 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export to XLSX\n",
    "df_scores.to_excel(\"Pipeline_scores.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Mean scores for Clean Regressor Pipeline: {df_scores['Clean Regressor'].mean()}\")\n",
    "print(f\"Mean scores for Dirty Regressor Pipeline: {df_scores['Dirty Regressor'].mean()}\")\n",
    "print(f\"Mean scores for Parallel Regressor Pipeline: {df_scores['Parallel Regressor'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### output definitive regressor parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "regg_final_output = {}\n",
    "for company, metrics_recall in results_dict_f1.items():\n",
    "    regg_final_output[company] = {}\n",
    "    regg_final_output[company]['params'] = {}\n",
    "    metrics_f1 = results_dict_f1[company]\n",
    "    \n",
    "    best_r2_parallel_f1 = -9999\n",
    "    \n",
    "    for paramset in metrics_recall:\n",
    "        if paramset == \"classifier\":\n",
    "            continue\n",
    "\n",
    "        r2_parallel_f1 = metrics_f1[paramset][\"paralel_regressor\"][\"r2_score\"]\n",
    "\n",
    "       \n",
    "        if r2_parallel_f1 > best_r2_parallel_f1:\n",
    "            best_r2_parallel_f1 = r2_parallel_f1\n",
    "            best_params_parallel_f1 = paramset\n",
    "    n_est = best_params_parallel_f1.split(\"_\")[0]\n",
    "    max_depth = best_params_parallel_f1.split(\"_\")[1]\n",
    "    learn_rate = best_params_parallel_f1.split(\"_\")[2]\n",
    "\n",
    "    regg_final_output[company]['params']['n_estimators'] = n_est\n",
    "    regg_final_output[company]['params']['max_depth'] = max_depth\n",
    "    regg_final_output[company]['params']['learning_rate'] = learn_rate\n",
    "\n",
    "# save file to a json file\n",
    "import json\n",
    "with open('reg_parameters_f1.json', 'w') as file:\n",
    "    json.dump(regg_final_output, file, indent=4)  # indent=4 is optional for pretty printing\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create definitive pipeline inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline_parameters = {}\n",
    "import json\n",
    "with open('class_parameters_recall.json', 'r') as file:\n",
    "    class_parameters = json.load(file)\n",
    "\n",
    "\n",
    "with open('reg_parameters_f1.json', 'r') as file:\n",
    "    recal_parameters = json.load(file)\n",
    "\n",
    "for company in class_parameters:\n",
    "    final_pipeline_parameters[company] = {}\n",
    "    final_pipeline_parameters[company]['fakename'] = class_parameters[company]['fakename'] \n",
    "    final_pipeline_parameters[company]['n_clusters'] = class_parameters[company]['nclusters']\n",
    "\n",
    "    final_pipeline_parameters[company]['class_parameters'] = {}\n",
    "    final_pipeline_parameters[company]['class_parameters']['learning_rate'] = float(class_parameters[company]['params']['learning_rate'])\n",
    "    final_pipeline_parameters[company]['class_parameters']['max_depth'] = int(class_parameters[company]['params']['max_depth'])\n",
    "    final_pipeline_parameters[company]['class_parameters']['n_estimators'] = int(class_parameters[company]['params']['n_estimators'])\n",
    "\n",
    "    final_pipeline_parameters[company]['regressor_parameters'] = {}\n",
    "    final_pipeline_parameters[company]['regressor_parameters']['learning_rate'] = float(recal_parameters[company]['params']['learning_rate'])\n",
    "    final_pipeline_parameters[company]['regressor_parameters']['max_depth'] = int(recal_parameters[company]['params']['max_depth'])\n",
    "    final_pipeline_parameters[company]['regressor_parameters']['n_estimators'] = int(recal_parameters[company]['params']['n_estimators'])\n",
    "\n",
    "# save final_dict to a json file\n",
    "\n",
    "with open('final_pipeline_parameters.json', 'w') as file:\n",
    "    json.dump(final_pipeline_parameters, file, indent=4)  # indent=4 is optional for pretty printing\n",
    "final_pipeline_parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solver-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
